{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Thanks to https://www.kaggle.com/xhlulu/ranzcr-efficientnet-tpu-training","metadata":{}},{"cell_type":"code","source":"!pip install efficientnet","metadata":{"execution":{"iopub.status.busy":"2021-08-08T02:48:02.494906Z","iopub.execute_input":"2021-08-08T02:48:02.495352Z","iopub.status.idle":"2021-08-08T02:48:11.878461Z","shell.execute_reply.started":"2021-08-08T02:48:02.495287Z","shell.execute_reply":"2021-08-08T02:48:11.877114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tf_clahe","metadata":{"execution":{"iopub.status.busy":"2021-08-08T02:48:11.8844Z","iopub.execute_input":"2021-08-08T02:48:11.884868Z","iopub.status.idle":"2021-08-08T02:48:19.628487Z","shell.execute_reply.started":"2021-08-08T02:48:11.884808Z","shell.execute_reply":"2021-08-08T02:48:19.62736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport tf_clahe\nimport efficientnet.tfkeras as efn\nimport random, re, math\nimport numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\nfrom sklearn.metrics import accuracy_score, roc_auc_score\n\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB7 as Efnb7\nimport tensorflow.keras.backend as K\n\nimport cv2\nimport albumentations as alb\n\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GroupKFold","metadata":{"execution":{"iopub.status.busy":"2021-08-08T02:48:19.632689Z","iopub.execute_input":"2021-08-08T02:48:19.633085Z","iopub.status.idle":"2021-08-08T02:48:28.339376Z","shell.execute_reply.started":"2021-08-08T02:48:19.633047Z","shell.execute_reply":"2021-08-08T02:48:28.338173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    \n    return strategy\n\n\ndef build_decoder(with_labels=True, target_size=(256, 256), ext='jpg', aug=False):\n    def decode(path):\n        file_bytes = tf.io.read_file(path)\n\n        if ext == 'png':\n            img = tf.image.decode_png(file_bytes, channels=3)\n        elif ext in ['jpg', 'jpeg']:\n            img = tf.image.decode_jpeg(file_bytes, channels=3)\n        else:\n            raise ValueError(\"Image extension not supported\")\n        \n        # if np.random.rand() <= 0.6:\n        #     img = tfa.image.random_hsv_in_yiq(img, max_delta_hue=4,\n        #                             lower_saturation=2, upper_saturation=4,\n        #                             lower_value=2, upper_value=4, seed=2021)\n        \n        if aug:\n            pass\n            #img = tf.image.random_flip_up_down(img)\n            #img = tf.image.random_flip_left_right(img)\n\n            #img = tf.image.random_brightness(img, 0.2)\n            #img = tf.image.adjust_gamma(img, 1.0, 1.0) \n            #img = tf.image.adjust_saturation(img, 0.2)\n        \n        \"\"\"\n        if np.random.rand() <= 0.6:\n            img = tf_clahe.clahe(img, tile_grid_size=(16, 16), clip_limit=6.0)\n            \n        if np.random.rand() <= 0.6:\n            img = tfa.image.sharpness(img, 6.0)\n        \n        # img = tfa.image.equalize(img)\n        # img = tf.image.random_contrast(img, 2, 4)\n        # img = tfa.image.mean_filter2d(img)\n        # img = tfa.image.median_filter2d(img)\\\n        \n        if np.random.rand() <= 0.6:\n            img = tfa.image.gaussian_filter2d(img, sigma=1.0, filter_shape=(4,4))\n        \"\"\"\n        img = tf.cast(img, tf.float32) / 255.0\n        img = tf.image.resize(img, target_size)\n\n        return img\n    \n    def decode_with_labels(path, label):\n        return decode(path), label\n    \n    return decode_with_labels if with_labels else decode\n\n\ndef build_augmenter(with_labels=True):\n    def augment(img):\n        img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_flip_left_right(img)\n        #img = tf.image.random_brightness(img, 0.3)\n        #img = tf.image.adjust_saturation(img, 0.5)\n        return img\n    \n    def augment_with_labels(img, label):\n        return augment(img), label\n    \n    return augment_with_labels if with_labels else augment\n\n\ndef build_dataset(paths, labels=None, bsize=128, cache=True,\n                  decode_fn=None, augment_fn=None,\n                  augment=True, repeat=True, shuffle=2048, \n                  cache_dir=\"\"):\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n    \n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n    \n    if augment_fn is None:\n        augment_fn = build_augmenter(labels is not None)\n    \n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = paths if labels is None else (paths, labels)\n    \n    dset = tf.data.Dataset.from_tensor_slices(slices)\n    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n    dset = dset.cache(cache_dir) if cache else dset\n    \n    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n    \n    # if np.random.rand() <= 0.6:\n    # dset = dset.map(transform, num_parallel_calls=AUTO) if augment else dset\n    \n    dset = dset.repeat() if repeat else dset\n    # dset = dset.batch(bsize)\n    \n    # dset = dset.map(transform2, num_parallel_calls=AUTO) if augment else dset\n    \n    # dset = dset.unbatch()\n    dset = dset.shuffle(shuffle) if shuffle else dset\n    dset = dset.batch(bsize).prefetch(AUTO)\n    \n    return dset","metadata":{"execution":{"iopub.status.busy":"2021-08-08T02:48:28.340933Z","iopub.execute_input":"2021-08-08T02:48:28.341353Z","iopub.status.idle":"2021-08-08T02:48:28.362954Z","shell.execute_reply.started":"2021-08-08T02:48:28.341307Z","shell.execute_reply":"2021-08-08T02:48:28.361696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n    # returns 3x3 transformmatrix which transforms indicies\n        \n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation / 180.\n    shear = math.pi * shear / 180.\n    \n    # ROTATION MATRIX\n    c1 = tf.math.cos(rotation)\n    s1 = tf.math.sin(rotation)\n    one = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n        \n    # SHEAR MATRIX\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)\n    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n    \n    # ZOOM MATRIX\n    zoom_matrix = tf.reshape( tf.concat([one/height_zoom,zero,zero, zero,one/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n    \n    # SHIFT MATRIX\n    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n    \n    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))","metadata":{"execution":{"iopub.status.busy":"2021-08-08T02:48:28.364765Z","iopub.execute_input":"2021-08-08T02:48:28.365156Z","iopub.status.idle":"2021-08-08T02:48:28.38032Z","shell.execute_reply.started":"2021-08-08T02:48:28.36512Z","shell.execute_reply":"2021-08-08T02:48:28.379483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform(image, label):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated, sheared, zoomed, and shifted\n    DIM = IMAGE_SIZE[0]\n    XDIM = DIM%2 #fix for size 331\n    \n    rot = 15. * tf.random.normal([1],dtype='float32')\n    shr = 5. * tf.random.normal([1],dtype='float32') \n    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n    h_shift = 16. * tf.random.normal([1],dtype='float32') \n    w_shift = 16. * tf.random.normal([1],dtype='float32') \n  \n    # GET TRANSFORMATION MATRIX\n    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n\n    # LIST DESTINATION PIXEL INDICES\n    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n    z = tf.ones([DIM*DIM],dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n    idx2 = K.cast(idx2,dtype='int32')\n    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n    \n    # FIND ORIGIN PIXEL VALUES           \n    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n    d = tf.gather_nd(image,tf.transpose(idx3))\n        \n    return tf.reshape(d,[DIM,DIM,3]),label","metadata":{"execution":{"iopub.status.busy":"2021-08-08T02:48:28.382105Z","iopub.execute_input":"2021-08-08T02:48:28.383023Z","iopub.status.idle":"2021-08-08T02:48:28.403414Z","shell.execute_reply.started":"2021-08-08T02:48:28.382925Z","shell.execute_reply":"2021-08-08T02:48:28.40104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def batch_mixup(images, labels, PROBABILITY=1.0, batch_size=0):\n\n    DIM = IMAGE_SIZE[0]\n    CLASSES = 4\n    \n    if batch_size == 0:\n        batch_size = BATCH_SIZE\n    \n    # Do `batch_mixup` with a probability = `PROBABILITY`\n    # This is a tensor containing 0 or 1 -- 0: no mixup.\n    # shape = [batch_size]\n    do_mixup = tf.cast(tf.random.uniform([batch_size], 0, 1) <= PROBABILITY, tf.int32)\n\n    # Choose random images in the batch for cutmix\n    # shape = [batch_size]\n    new_image_indices = tf.cast(tf.random.uniform([batch_size], 0, batch_size), tf.int32)\n    \n    # ratio of importance of the 2 images to be mixed up\n    # shape = [batch_size]\n    a = tf.random.uniform([batch_size], 0, 1) * tf.cast(do_mixup, tf.float32)  # this is beta dist with alpha=1.0\n                \n    # The second part corresponds to the images to be added to the original images `images`.\n    new_images =  (1-a)[:, tf.newaxis, tf.newaxis, tf.newaxis] * images + a[:, tf.newaxis, tf.newaxis, tf.newaxis] * tf.gather(images, new_image_indices)\n\n    # Make labels\n    if len(labels.shape) == 1:\n        labels = tf.one_hot(labels, CLASSES)\n    new_labels =  (1-a)[:, tf.newaxis] * labels + a[:, tf.newaxis] * tf.gather(labels, new_image_indices)\n\n    return new_images, new_labels","metadata":{"execution":{"iopub.status.busy":"2021-08-08T02:48:28.405361Z","iopub.execute_input":"2021-08-08T02:48:28.405925Z","iopub.status.idle":"2021-08-08T02:48:28.422678Z","shell.execute_reply.started":"2021-08-08T02:48:28.405871Z","shell.execute_reply":"2021-08-08T02:48:28.421707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def batch_cutmix(images, labels, PROBABILITY=1.0, batch_size=0):\n    \n    DIM = IMAGE_SIZE[0]\n    CLASSES = 4\n    \n    if batch_size == 0:\n        batch_size = BATCH_SIZE\n    \n    # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n    # This is a tensor containing 0 or 1 -- 0: no cutmix.\n    # shape = [batch_size]\n    do_cutmix = tf.cast(tf.random.uniform([batch_size], 0, 1) <= PROBABILITY, tf.int32)\n    \n    # Choose random images in the batch for cutmix\n    # shape = [batch_size]\n    new_image_indices = tf.cast(tf.random.uniform([batch_size], 0, batch_size), tf.int32)\n    \n    # Choose random location in the original image to put the new images\n    # shape = [batch_size]\n    new_x = tf.cast(tf.random.uniform([batch_size], 0, DIM), tf.int32)\n    new_y = tf.cast(tf.random.uniform([batch_size], 0, DIM), tf.int32)\n    \n    # Random width for new images, shape = [batch_size]\n    b = tf.random.uniform([batch_size], 0, 1) # this is beta dist with alpha=1.0\n    new_width = tf.cast(DIM * tf.math.sqrt(1-b), tf.int32) * do_cutmix\n    \n    # shape = [batch_size]\n    new_y0 = tf.math.maximum(0, new_y - new_width // 2)\n    new_y1 = tf.math.minimum(DIM, new_y + new_width // 2)\n    new_x0 = tf.math.maximum(0, new_x - new_width // 2)\n    new_x1 = tf.math.minimum(DIM, new_x + new_width // 2)\n    \n    # shape = [batch_size, DIM]\n    target = tf.broadcast_to(tf.range(DIM), shape=(batch_size, DIM))\n    \n    # shape = [batch_size, DIM]\n    mask_y = tf.math.logical_and(new_y0[:, tf.newaxis] <= target, target <= new_y1[:, tf.newaxis])\n    \n    # shape = [batch_size, DIM]\n    mask_x = tf.math.logical_and(new_x0[:, tf.newaxis] <= target, target <= new_x1[:, tf.newaxis])    \n    \n    # shape = [batch_size, DIM, DIM]\n    mask = tf.cast(tf.math.logical_and(mask_y[:, :, tf.newaxis], mask_x[:, tf.newaxis, :]), tf.float32)\n\n    # All components are of shape [batch_size, DIM, DIM, 3]\n    new_images =  images * tf.broadcast_to(1 - mask[:, :, :, tf.newaxis], [batch_size, DIM, DIM, 3]) + \\\n                    tf.gather(images, new_image_indices) * tf.broadcast_to(mask[:, :, :, tf.newaxis], [batch_size, DIM, DIM, 3])\n\n    a = tf.cast(new_width ** 2 / DIM ** 2, tf.float32)    \n        \n    # Make labels\n    if len(labels.shape) == 1:\n        labels = tf.one_hot(labels, CLASSES)\n        \n    new_labels =  (1-a)[:, tf.newaxis] * labels + a[:, tf.newaxis] * tf.gather(labels, new_image_indices)        \n        \n    return new_images, new_labels","metadata":{"execution":{"iopub.status.busy":"2021-08-08T02:48:28.426506Z","iopub.execute_input":"2021-08-08T02:48:28.427208Z","iopub.status.idle":"2021-08-08T02:48:28.446865Z","shell.execute_reply.started":"2021-08-08T02:48:28.427155Z","shell.execute_reply":"2021-08-08T02:48:28.445749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform2(image, label):\n    # THIS FUNCTION APPLIES BOTH CUTMIX AND MIXUP\n    DIM = IMAGE_SIZE[0]\n    CLASSES = 4\n    SWITCH = 0.5\n    CUTMIX_PROB = 0.7\n    MIXUP_PROB = -1.0\n    # FOR SWITCH PERCENT OF TIME WE DO CUTMIX AND (1-SWITCH) WE DO MIXUP\n    image2, label2 = batch_cutmix(image, label, CUTMIX_PROB)\n    image3, label3 = batch_mixup(image, label, MIXUP_PROB)\n    imgs = []; labs = []\n    for j in range(AUG_BATCH):\n        P = tf.cast( tf.random.uniform([],0,1)<=SWITCH, tf.float32)\n        imgs.append(P*image2[j,]+(1-P)*image3[j,])\n        labs.append(P*label2[j,]+(1-P)*label3[j,])\n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image4 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n    label4 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n    return image4,label4","metadata":{"execution":{"iopub.status.busy":"2021-08-08T02:48:28.448616Z","iopub.execute_input":"2021-08-08T02:48:28.449018Z","iopub.status.idle":"2021-08-08T02:48:28.458108Z","shell.execute_reply.started":"2021-08-08T02:48:28.448982Z","shell.execute_reply":"2021-08-08T02:48:28.457285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#COMPETITION_NAME = \"siimcovid19-512-img-png-600-study-png\"\nCOMPETITION_NAME = \"617-pseudo-labelling\"\n\nDATASET=1\nstrategy = auto_select_accelerator()\nBATCH_SIZE = 4 * strategy.num_replicas_in_sync\nGCS_DS_PATH = KaggleDatasets().get_gcs_path(COMPETITION_NAME)\n\nload_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\ntrain_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')\nohe_hot_df = pd.read_csv('../input/617-pseudo-labelling/617_Pseudo_Labelling.csv')\ndf=pd.concat([train_df, ohe_hot_df], ignore_index=True)\n\nlabel_cols = df.columns[1:5]\n\ngkf  = GroupKFold(n_splits = 5)\ndf['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(gkf.split(df, groups = df.id.tolist())):\n    df.loc[val_idx, 'fold'] = fold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COMPETITION_NAME = \"siimcovid19-1024-img-png-1024-study-png\"\n\nDATASET=1\nstrategy = auto_select_accelerator()\nBATCH_SIZE = strategy.num_replicas_in_sync * 4\nGCS_DS_PATH = KaggleDatasets().get_gcs_path(COMPETITION_NAME)\n\nload_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\ndf = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')\nlabel_cols = df.columns[1:5]\n\ngkf  = GroupKFold(n_splits = 5)\ndf['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(gkf.split(df, groups = df.id.tolist())):\n    df.loc[val_idx, 'fold'] = fold","metadata":{"execution":{"iopub.status.busy":"2021-08-08T02:48:28.459354Z","iopub.execute_input":"2021-08-08T02:48:28.459811Z","iopub.status.idle":"2021-08-08T02:48:34.620597Z","shell.execute_reply.started":"2021-08-08T02:48:28.459774Z","shell.execute_reply":"2021-08-08T02:48:34.619653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GCS_DS_PATH","metadata":{"execution":{"iopub.status.busy":"2021-08-08T02:48:34.621805Z","iopub.execute_input":"2021-08-08T02:48:34.622094Z","iopub.status.idle":"2021-08-08T02:48:34.63261Z","shell.execute_reply.started":"2021-08-08T02:48:34.622066Z","shell.execute_reply":"2021-08-08T02:48:34.631625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COMPETITION_NAME = \"siimcovid19-600-study-only-jpg-extend\"\nDATASET=2\nstrategy = auto_select_accelerator()\nBATCH_SIZE = 4 * strategy.num_replicas_in_sync\nGCS_DS_PATH = KaggleDatasets().get_gcs_path(COMPETITION_NAME)\n\nload_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\nlabel_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')\nlabel_cols = label_df.columns[1:5]\n\ndf = pd.read_csv('../input/siimcovid19-600-study-only-jpg-extend/df.csv').drop(['Unnamed: 0'], axis=1)\nfor index in range(df['id'].shape[0]):\n    df['id'].iloc[index] = df['id'].iloc[index].replace(\".dcm.jpg\", \"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Learning rate schedule for TPU, GPU and CPU.\n# Using an LR ramp up because fine-tuning a pre-trained model.\n# Starting with a high LR would break the pre-trained weights.\n\nIMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)\nIMS = 7\nAUG_BATCH = BATCH_SIZE\nIMAGE_SIZE = [IMSIZE[IMS], IMSIZE[IMS]]\nEPOCHS=20\nLR_START =  0.00001\nLR_MAX =  0.00005 * strategy.num_replicas_in_sync\nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = 5\nLR_SUSTAIN_EPOCHS = 0\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n\nrng = [i for i in range(20 if EPOCHS<20 else EPOCHS)]\ny = [lrfn(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2021-08-08T02:48:34.634145Z","iopub.execute_input":"2021-08-08T02:48:34.634489Z","iopub.status.idle":"2021-08-08T02:48:34.847182Z","shell.execute_reply.started":"2021-08-08T02:48:34.63446Z","shell.execute_reply":"2021-08-08T02:48:34.846217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nall_labels = []\nall_prob = []\nall_pred = []\n\nfor i in range(5):\n    \n    if DATASET==1:\n        valid_paths = GCS_DS_PATH + '/study/' + df[df['fold'] == i]['id'] + '.png' #\"/train/\"\n        train_paths = GCS_DS_PATH + '/study/' + df[df['fold'] != i]['id'] + '.png' #\"/train/\"\n    \n    elif DATASET==2:\n        valid_paths = GCS_DS_PATH + '/test/' + df[df['fold'] == i]['id'] + '.jpg' #\"/train/\"\n        train_paths = GCS_DS_PATH + '/test/' + df[df['fold'] != i]['id'] + '.jpg' #\"/train/\"\n    \n    valid_labels = tf.cast(df[df['fold'] == i][label_cols].values, tf.float32)\n    train_labels = tf.cast(df[df['fold'] != i][label_cols].values, tf.float32)\n    \n    decoder = build_decoder(with_labels=True, \n                            target_size=(IMSIZE[IMS], IMSIZE[IMS]), ext='png', aug=True)\n    \n    val_decoder = build_decoder(with_labels=True, \n                            target_size=(IMSIZE[IMS], IMSIZE[IMS]), ext='png', aug=False)\n    \n    test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[IMS], IMSIZE[IMS]),ext='png')\n\n    train_dataset = build_dataset(\n        train_paths, train_labels, bsize=BATCH_SIZE, decode_fn=decoder\n    )\n\n    valid_dataset = build_dataset(\n        valid_paths, valid_labels, bsize=BATCH_SIZE, decode_fn=val_decoder,\n        repeat=False, shuffle=False, augment=False\n    )\n\n    try:\n        n_labels = train_labels.shape[1]\n    except:\n        n_labels = 1\n\n    with strategy.scope():\n        input_tensor = tf.keras.layers.Input(shape=(IMSIZE[IMS], IMSIZE[IMS], 3))\n        base_model = efn.EfficientNetB7(input_tensor=input_tensor, \n                                        weights='noisy-student',\n                                        include_top=False)\n        bm_output = base_model.output\n        \n        x = tf.keras.layers.GlobalAveragePooling2D()(bm_output)\n        x = tf.keras.layers.Dropout(0.5)(x)\n        output = tf.keras.layers.Dense(n_labels, activation='softmax', dtype='float32')(x)\n        \n        model = tf.keras.models.Model(inputs=input_tensor, outputs=output)\n\n        model.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n            loss='categorical_crossentropy',\n            metrics=['categorical_accuracy', tf.keras.metrics.AUC(name='auc', multi_label=True)]\n        )\n\n    steps_per_epoch = train_paths.shape[0] // BATCH_SIZE\n     \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        f'model{i}.h5', save_best_only=False, \n        monitor='val_loss', mode='min') # val_categorical_accuracy, max\n    \n    early_stopping = tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss', patience=15, verbose=1, mode='min'\n    )\n    \n    lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor=\"val_loss\", patience=5, min_lr=1e-6, mode='min')\n    \n    print(f'######## Start of {i+1} Fold ########')\n    history = model.fit(\n        train_dataset,\n        #epochs=EPOCHS,\n        epochs=100,\n        verbose=2,                        # lr_callback, early_stopping\n        #callbacks=[checkpoint, lr_callback],\n        callbacks=[checkpoint, lr_reducer, early_stopping],\n        steps_per_epoch=steps_per_epoch,\n        validation_data=valid_dataset)\n    \n    hist_df = pd.DataFrame(history.history)\n    hist_df.to_csv(f'history{i}.csv')\n    print(f'######## End of {i+1} Fold ########')\n    \n    prob = model.predict(valid_dataset, verbose=1)\n    all_labels.append(np.argmax(valid_labels, axis=-1))\n    all_prob.append(prob)\n    all_pred.append(np.argmax(prob, axis=-1))\n    \ncm_correct_labels = np.concatenate(all_labels)\ncm_probabilities = np.concatenate(all_prob)\ncm_predictions = np.concatenate(all_pred)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T02:48:34.848579Z","iopub.execute_input":"2021-08-08T02:48:34.848887Z","iopub.status.idle":"2021-08-08T06:37:39.192251Z","shell.execute_reply.started":"2021-08-08T02:48:34.848857Z","shell.execute_reply":"2021-08-08T06:37:39.189137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cmat = confusion_matrix(cm_correct_labels, cm_predictions, labels=range(n_labels))\nscore = f1_score(cm_correct_labels, cm_predictions, labels=range(n_labels), average='macro')\nprecision = precision_score(cm_correct_labels, cm_predictions, labels=range(n_labels), average='macro')\nrecall = recall_score(cm_correct_labels, cm_predictions, labels=range(n_labels), average='macro')\nacc = accuracy_score(cm_correct_labels, cm_predictions)\n# display_confusion_matrix(cmat, score, precision, recall)\nprint('accuracy: {:.3f}, f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(acc, score, precision, recall)); print()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:37:39.197867Z","iopub.execute_input":"2021-08-08T06:37:39.198209Z","iopub.status.idle":"2021-08-08T06:37:39.223774Z","shell.execute_reply.started":"2021-08-08T06:37:39.198177Z","shell.execute_reply":"2021-08-08T06:37:39.222538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}