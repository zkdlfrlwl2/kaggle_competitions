{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"COTS YOLOv5 - Trianing.ipynb","provenance":[],"collapsed_sections":["WCrFb7a7THKW","pJOJkUGbbz90","KEPFKoYfGNXi"],"machine_shape":"hm","mount_file_id":"1d8B8uS1Vz10DKtc8iC9Sqt2kgGsEJGKU","authorship_tag":"ABX9TyMOHtc4zc3eBRmy155fRXlm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"fb16e082c3644230a929ec7c2cd38967":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_761fc6965cae4e3ea3280074396c97bb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_eebf78a147564cffb290669a89cfe842","IPY_MODEL_ee8197d94eb54b87b1d8d3f64d9bf99e","IPY_MODEL_454b2651343444d3a291e6d756a034bd"]}},"761fc6965cae4e3ea3280074396c97bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eebf78a147564cffb290669a89cfe842":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0face7d5b39148efb7a52bfc9d2d9098","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_960ad9307c6a4a1698f4cf4498e30778"}},"ee8197d94eb54b87b1d8d3f64d9bf99e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5ce6a9e3e61a49e7b65b580cf029f657","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":23501,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":23501,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_960e39373a9942bca3a5d488eabdfb50"}},"454b2651343444d3a291e6d756a034bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_156a9eae2fe04c49a8d381c6ff95cebe","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 23501/23501 [00:00&lt;00:00, 57393.21it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aba32ab19a1549dfaac1a9791b3dcbe6"}},"0face7d5b39148efb7a52bfc9d2d9098":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"960ad9307c6a4a1698f4cf4498e30778":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ce6a9e3e61a49e7b65b580cf029f657":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"960e39373a9942bca3a5d488eabdfb50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"156a9eae2fe04c49a8d381c6ff95cebe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aba32ab19a1549dfaac1a9791b3dcbe6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"640b7b82ede944618c124b142e0db9be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_681179465b78498cb201c8924b51cc4c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_18bc723c95cd4ca69fed9854059b089e","IPY_MODEL_f3ec1003ea4240148acd0551830a5d45","IPY_MODEL_c96743649ed44701ad869a1b288b6f37"]}},"681179465b78498cb201c8924b51cc4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"18bc723c95cd4ca69fed9854059b089e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7e2792f7fbc04409bdb72930962aa440","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_45cc8058cb84445f84529214f21eb601"}},"f3ec1003ea4240148acd0551830a5d45":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8ff9d66be66049d5aead9826fa6c4231","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":23501,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":23501,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e34a86123514d779918e1505743fa6a"}},"c96743649ed44701ad869a1b288b6f37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_42f36aa7abcb449e9cb085a44ce95cd2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 23501/23501 [00:00&lt;00:00, 81313.99it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c17b802f9d1045b8a0521a59c4442cee"}},"7e2792f7fbc04409bdb72930962aa440":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"45cc8058cb84445f84529214f21eb601":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ff9d66be66049d5aead9826fa6c4231":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2e34a86123514d779918e1505743fa6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"42f36aa7abcb449e9cb085a44ce95cd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c17b802f9d1045b8a0521a59c4442cee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a250048178ee4f5ab78afe7c532e857e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9c44d386cfcc4a4b8141856e95980447","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5f05c72ced5a4f2ab9db9f18d936e95a","IPY_MODEL_4b675577ca0943389d28012943436d70","IPY_MODEL_8e1543a08bf04b8a8371cab5f3ea9b4e"]}},"9c44d386cfcc4a4b8141856e95980447":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5f05c72ced5a4f2ab9db9f18d936e95a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a1db02f89ae84920a7187cee4afa5381","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8888702ebdc3453ba213c0ba9fe8f717"}},"4b675577ca0943389d28012943436d70":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_830814b0789c45728f0c10130bf95c1a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4919,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4919,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a896926b99b44ad8be01e70b3c2eba4d"}},"8e1543a08bf04b8a8371cab5f3ea9b4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_df5298b4cf234f069fbf92343ea097ee","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4919/4919 [00:04&lt;00:00, 1276.33it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_80b6a2457ae847cc836a562dc63753d5"}},"a1db02f89ae84920a7187cee4afa5381":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8888702ebdc3453ba213c0ba9fe8f717":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"830814b0789c45728f0c10130bf95c1a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a896926b99b44ad8be01e70b3c2eba4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"df5298b4cf234f069fbf92343ea097ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"80b6a2457ae847cc836a562dc63753d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6963e3e6e6f84fcf9deea4526a25f84a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_557d50c4a3894af9aca72314d4cdc3d8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_13b7c37af3fe47d1811866c997a28296","IPY_MODEL_132e3655d32e42a2bc4fb85d0f8fd7f3","IPY_MODEL_462976da66534c82b88dc06652609e9d"]}},"557d50c4a3894af9aca72314d4cdc3d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"13b7c37af3fe47d1811866c997a28296":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_567d03cdd1a94c79aa3cc24b1ec6248d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d82545819d8439486415f72f446af68"}},"132e3655d32e42a2bc4fb85d0f8fd7f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_74b4397eabca4260bc89b00859af90f4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4919,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4919,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b722e1ee192241408423bb4b69d16bbe"}},"462976da66534c82b88dc06652609e9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3c164cfe0f1b408d9bed1831fb5d952b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4919/4919 [00:24&lt;00:00, 759.95it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7e24de8c3a624ec1be5f8d144f863446"}},"567d03cdd1a94c79aa3cc24b1ec6248d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5d82545819d8439486415f72f446af68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74b4397eabca4260bc89b00859af90f4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b722e1ee192241408423bb4b69d16bbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c164cfe0f1b408d9bed1831fb5d952b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7e24de8c3a624ec1be5f8d144f863446":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"346d84da3ce3410fa739381445b3504d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ed7cdc2c06fb40dca5813fdd6999bbc6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_949bad847672436eb7d12d7ddc23c68e","IPY_MODEL_765bcefc4af842b3b2154f6c91917ffc","IPY_MODEL_fff2693c2f724939b54921047e897e60"]}},"ed7cdc2c06fb40dca5813fdd6999bbc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"949bad847672436eb7d12d7ddc23c68e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_64128eb117854d2890327de0a76d9c7a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_24ed95e99a80420eb956c0b171d439b0"}},"765bcefc4af842b3b2154f6c91917ffc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_70f8039a836a42be883f615bd7f09e04","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4919,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4919,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2ecb75f2b7864f4ba9ab711124cb51cd"}},"fff2693c2f724939b54921047e897e60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b5246c86aebb4cb1a50905ec834af9e2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4919/4919 [00:02&lt;00:00, 2201.67it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_09f52573ecbf489089354b32b8aac826"}},"64128eb117854d2890327de0a76d9c7a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"24ed95e99a80420eb956c0b171d439b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"70f8039a836a42be883f615bd7f09e04":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2ecb75f2b7864f4ba9ab711124cb51cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5246c86aebb4cb1a50905ec834af9e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"09f52573ecbf489089354b32b8aac826":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","source":["## Hardward Check"],"metadata":{"id":"SiljiuIAcPE3"}},{"cell_type":"code","source":["!head /proc/cpuinfo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZdzNrvecTM3","executionInfo":{"status":"ok","timestamp":1643286567256,"user_tz":-540,"elapsed":525,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"b46b3083-e22d-4b87-e0b8-afd299b404b4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n"]}]},{"cell_type":"code","source":["!head -n 3 /proc/meminfo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FsCLDaqYcUeN","executionInfo":{"status":"ok","timestamp":1643286568669,"user_tz":-540,"elapsed":973,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"91785039-548c-427c-ad20-f79ad4ae667a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["MemTotal:       26696412 kB\n","MemFree:        23341436 kB\n","MemAvailable:   25289424 kB\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHA8P7ogcVi5","executionInfo":{"status":"ok","timestamp":1643286568670,"user_tz":-540,"elapsed":7,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"197e6e0c-1fb4-40ea-9fa6-1ee8dfd311c0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Jan 27 12:29:28 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["## Import "],"metadata":{"id":"kYONxEUPNITZ"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"Uap7H-QUJlwE","executionInfo":{"status":"ok","timestamp":1643286575230,"user_tz":-540,"elapsed":5634,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}}},"outputs":[],"source":["import ast\n","import os\n","import json\n","import pandas as pd\n","import torch\n","import importlib\n","import cv2\n","import warnings\n","import numpy as np\n","\n","from shutil import copyfile\n","from tqdm.notebook import tqdm\n","tqdm.pandas()\n","from PIL import Image\n","from string import Template\n","from IPython.display import display\n","import matplotlib.pyplot as plt\n","from IPython.display import display, HTML\n","from matplotlib import animation, rc\n","\n","warnings.filterwarnings('ignore')\n","\n","%matplotlib inline"]},{"cell_type":"code","source":["BASE_PATH='/content/drive/MyDrive/Colab/Great-Barrier-Reef/data/cross-validation'\n","\n","train_df = pd.read_csv(os.path.join(BASE_PATH, 'train-5folds-v3.csv'))\n","#train_df = pd.read_csv(os.path.join(BASE_PATH, 'train-10folds-v3.csv'))\n","FOLD = 2\n","\n","#train_df = pd.read_csv('/content/drive/MyDrive/Colab/Great-Barrier-Reef/data/train-validation-split/train-0.2.csv')\n","train_df['old_image_path'] = '/content/train_images/' + \"video_\" + train_df['video_id'].astype(str) + \"/\" + train_df['video_frame'].astype(str) + \".jpg\""],"metadata":{"id":"pQnnaegcOay1","executionInfo":{"status":"ok","timestamp":1643286576169,"user_tz":-540,"elapsed":9,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# check Torch and Cuda version\n","print(f'Torch: {torch.__version__}')\n","!nvcc --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ENV7E-0iS4_v","executionInfo":{"status":"ok","timestamp":1643286576169,"user_tz":-540,"elapsed":9,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"c5499fc9-d8b0-4194-9ceb-3c0b5f423d22"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Torch: 1.10.0+cu111\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Mon_Oct_12_20:09:46_PDT_2020\n","Cuda compilation tools, release 11.1, V11.1.105\n","Build cuda_11.1.TC455_06.29190527_0\n"]}]},{"cell_type":"code","source":["%%time\n","zip_path = '/content/drive/MyDrive/Colab/Great-Barrier-Reef/data/tensorflow-great-barrier-reef.zip'\n","!cp '{zip_path}' ./\n","!unzip -q tensorflow-great-barrier-reef.zip\n","!rm tensorflow-great-barrier-reef.zip\n","!ls"],"metadata":{"id":"UaBEurEAfIGT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643287076530,"user_tz":-540,"elapsed":500365,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"a0e35a9e-28b0-4c4e-c2f5-6607af90f789"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["drive\t\t\t       example_test.npy  sample_data  train.csv\n","example_sample_submission.csv  greatbarrierreef  test.csv     train_images\n","CPU times: user 2.96 s, sys: 482 ms, total: 3.44 s\n","Wall time: 8min 20s\n"]}]},{"cell_type":"markdown","source":["## 1. Install YOLOv5"],"metadata":{"id":"WCrFb7a7THKW"}},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/yolov5\n","\n","%cd yolov5\n","!pip install -r requirements.txt"],"metadata":{"id":"a3tnWmnWTD0O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9aFMaAwgfWmz","executionInfo":{"status":"ok","timestamp":1640493866428,"user_tz":-540,"elapsed":42,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"4d37f09b-85e1-482d-e3fb-f0ad15bf2998"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"markdown","source":["## Copy YOLOv5"],"metadata":{"id":"XYjEPLdl4Z7t"}},{"cell_type":"code","source":["!cp -r /content/drive/MyDrive/Colab/Great-Barrier-Reef/yolov5 /content/yolov5\n","\n","%cd yolov5\n","!pip install -r requirements.txt\n","%cd /content"],"metadata":{"id":"Qv7AXq6wBgEP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643287111358,"user_tz":-540,"elapsed":34832,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"01fdf85b-d85c-4819-ba67-e1b72772b35f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n","Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n","Collecting PyYAML>=5.3.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.23.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.10.0+cu111)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.11.1+cu111)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.62.3)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (2.7.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.1.5)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (0.11.2)\n","Collecting thop\n","  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.10.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (3.10.0.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.6)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (57.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.3.6)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.37.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.43.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.17.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.6.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 20)) (2018.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.15.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.10.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.1.1)\n","Installing collected packages: thop, PyYAML\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-6.0 thop-0.0.31.post2005241907\n","/content\n"]}]},{"cell_type":"markdown","source":["## 2. Prepare COTS dataset for YOLOv5\n","### A. Prepare dataset and annotations"],"metadata":{"id":"MyxvpR-2TuWI"}},{"cell_type":"code","source":["def get_bbox(annots):\n","    bboxes = [list(annot.values()) for annot in annots]\n","    return bboxes\n","\n","# Annotations\n","train_df['annotations'] = train_df['annotations'].progress_apply(lambda x: ast.literal_eval(x))\n","train_df['bboxes'] = train_df.annotations.progress_apply(get_bbox)\n","\n","#Images resolution\n","train_df[\"width\"] = 1280\n","train_df[\"height\"] = 720"],"metadata":{"id":"YAt2ICsuTr9G","colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["fb16e082c3644230a929ec7c2cd38967","761fc6965cae4e3ea3280074396c97bb","eebf78a147564cffb290669a89cfe842","ee8197d94eb54b87b1d8d3f64d9bf99e","454b2651343444d3a291e6d756a034bd","0face7d5b39148efb7a52bfc9d2d9098","960ad9307c6a4a1698f4cf4498e30778","5ce6a9e3e61a49e7b65b580cf029f657","960e39373a9942bca3a5d488eabdfb50","156a9eae2fe04c49a8d381c6ff95cebe","aba32ab19a1549dfaac1a9791b3dcbe6","640b7b82ede944618c124b142e0db9be","681179465b78498cb201c8924b51cc4c","18bc723c95cd4ca69fed9854059b089e","f3ec1003ea4240148acd0551830a5d45","c96743649ed44701ad869a1b288b6f37","7e2792f7fbc04409bdb72930962aa440","45cc8058cb84445f84529214f21eb601","8ff9d66be66049d5aead9826fa6c4231","2e34a86123514d779918e1505743fa6a","42f36aa7abcb449e9cb085a44ce95cd2","c17b802f9d1045b8a0521a59c4442cee"]},"executionInfo":{"status":"ok","timestamp":1643287111938,"user_tz":-540,"elapsed":589,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"773d3272-d611-4523-d2fd-9b314e38e103"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb16e082c3644230a929ec7c2cd38967","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/23501 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"640b7b82ede944618c124b142e0db9be","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/23501 [00:00<?, ?it/s]"]},"metadata":{}}]},{"cell_type":"markdown","source":["### Helper Function"],"metadata":{"id":"ancNSTTc30aa"}},{"cell_type":"code","source":["def voc2yolo(image_height, image_width, bboxes):\n","    \"\"\"\n","    voc  => [x1, y1, x2, y1]\n","    yolo => [xmid, ymid, w, h] (normalized)\n","    \"\"\"\n","    \n","    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n","    \n","    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]/ image_width\n","    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]/ image_height\n","    \n","    w = bboxes[..., 2] - bboxes[..., 0]\n","    h = bboxes[..., 3] - bboxes[..., 1]\n","    \n","    bboxes[..., 0] = bboxes[..., 0] + w/2\n","    bboxes[..., 1] = bboxes[..., 1] + h/2\n","    bboxes[..., 2] = w\n","    bboxes[..., 3] = h\n","    \n","    return bboxes\n","\n","def yolo2voc(image_height, image_width, bboxes):\n","    \"\"\"\n","    yolo => [xmid, ymid, w, h] (normalized)\n","    voc  => [x1, y1, x2, y1]\n","    \n","    \"\"\" \n","    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n","    \n","    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n","    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n","    \n","    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n","    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n","    \n","    return bboxes\n","\n","def coco2yolo(image_height, image_width, bboxes):\n","    \"\"\"\n","    coco => [xmin, ymin, w, h]\n","    yolo => [xmid, ymid, w, h] (normalized)\n","    \"\"\"\n","    \n","    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n","    \n","    # normolizinig\n","    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]/ image_width\n","    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]/ image_height\n","    \n","    # converstion (xmin, ymin) => (xmid, ymid)\n","    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]/2\n","    \n","    return bboxes\n","\n","def yolo2coco(image_height, image_width, bboxes):\n","    \"\"\"\n","    yolo => [xmid, ymid, w, h] (normalized)\n","    coco => [xmin, ymin, w, h]\n","    \n","    \"\"\" \n","    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n","    \n","    # denormalizing\n","    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]* image_width\n","    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]* image_height\n","    \n","    # converstion (xmid, ymid) => (xmin, ymin) \n","    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n","    \n","    return bboxes\n","\n","\n","def load_image(image_path):\n","    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n","\n","\n","def plot_one_box(x, img, color=None, label=None, line_thickness=None):\n","    # Plots one bounding box on image img\n","    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n","    color = color or [random.randint(0, 255) for _ in range(3)]\n","    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n","    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n","    if label:\n","        tf = max(tl - 1, 1)  # font thickness\n","        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n","        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n","        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n","        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n","\n","def draw_bboxes(img, bboxes, classes, class_ids, colors = None, show_classes = None, bbox_format = 'yolo', class_name = False, line_thickness = 2):  \n","     \n","    image = img.copy()\n","    show_classes = classes if show_classes is None else show_classes\n","    colors = (0, 255 ,0) if colors is None else colors\n","    \n","    if bbox_format == 'yolo':\n","        \n","        for idx in range(len(bboxes)):  \n","            \n","            bbox  = bboxes[idx]\n","            cls   = classes[idx]\n","            cls_id = class_ids[idx]\n","            color = colors[cls_id] if type(colors) is list else colors\n","            \n","            if cls in show_classes:\n","            \n","                x1 = round(float(bbox[0])*image.shape[1])\n","                y1 = round(float(bbox[1])*image.shape[0])\n","                w  = round(float(bbox[2])*image.shape[1]/2) #w/2 \n","                h  = round(float(bbox[3])*image.shape[0]/2)\n","\n","                voc_bbox = (x1-w, y1-h, x1+w, y1+h)\n","                plot_one_box(voc_bbox, \n","                             image,\n","                             color = color,\n","                             label = cls if class_name else str(get_label(cls)),\n","                             line_thickness = line_thickness)\n","            \n","    elif bbox_format == 'coco':\n","        \n","        for idx in range(len(bboxes)):  \n","            \n","            bbox  = bboxes[idx]\n","            cls   = classes[idx]\n","            cls_id = class_ids[idx]\n","            color = colors[cls_id] if type(colors) is list else colors\n","            \n","            if cls in show_classes:            \n","                x1 = int(round(bbox[0]))\n","                y1 = int(round(bbox[1]))\n","                w  = int(round(bbox[2]))\n","                h  = int(round(bbox[3]))\n","\n","                voc_bbox = (x1, y1, x1+w, y1+h)\n","                plot_one_box(voc_bbox, \n","                             image,\n","                             color = color,\n","                             label = cls if class_name else str(cls_id),\n","                             line_thickness = line_thickness)\n","\n","    elif bbox_format == 'voc_pascal':\n","        \n","        for idx in range(len(bboxes)):  \n","            \n","            bbox  = bboxes[idx]\n","            cls   = classes[idx]\n","            cls_id = class_ids[idx]\n","            color = colors[cls_id] if type(colors) is list else colors\n","            \n","            if cls in show_classes: \n","                x1 = int(round(bbox[0]))\n","                y1 = int(round(bbox[1]))\n","                x2 = int(round(bbox[2]))\n","                y2 = int(round(bbox[3]))\n","                voc_bbox = (x1, y1, x2, y2)\n","                plot_one_box(voc_bbox, \n","                             image,\n","                             color = color,\n","                             label = cls if class_name else str(cls_id),\n","                             line_thickness = line_thickness)\n","    else:\n","        raise ValueError('wrong bbox format')\n","\n","    return image\n","\n","def get_bbox(annots):\n","    bboxes = [list(annot.values()) for annot in annots]\n","    return bboxes\n","\n","def get_imgsize(row):\n","    row['width'], row['height'] = imagesize.get(row['image_path'])\n","    return row\n","\n","\n","# https://www.kaggle.com/diegoalejogm/great-barrier-reefs-eda-with-animations\n","def create_animation(ims):\n","    fig = plt.figure(figsize=(16, 12))\n","    plt.axis('off')\n","    im = plt.imshow(ims[0])\n","\n","    def animate_func(i):\n","        im.set_array(ims[i])\n","        return [im]\n","\n","    return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1000//12)\n","\n","np.random.seed(32)\n","colors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n","          for idx in range(1)]"],"metadata":{"id":"MKjTndMt33Kc","executionInfo":{"status":"ok","timestamp":1643287112234,"user_tz":-540,"elapsed":298,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### Make directory"],"metadata":{"id":"kIHtPQOGrQRF"}},{"cell_type":"code","source":["HOME_DIR = '/content/'\n","IMAGE_DIR = 'dataset/images'\n","LABEL_DIR = 'dataset/labels'\n","\n","!mkdir {HOME_DIR}dataset\n","!mkdir {HOME_DIR}{IMAGE_DIR}\n","!mkdir {HOME_DIR}{LABEL_DIR}"],"metadata":{"id":"f5oytMLYWJUG","executionInfo":{"status":"ok","timestamp":1643287112555,"user_tz":-540,"elapsed":325,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["### Extra. Remove unlabeled data"],"metadata":{"id":"1YbJ-bVHj9hn"}},{"cell_type":"code","source":["#print(train_df.is_train.value_counts())\n","print(train_df.fold.value_counts())\n","train_df.drop(train_df[train_df['n_annotations']==0].index, inplace=True)\n","#print(train_df.is_train.value_counts())\n","print(train_df.fold.value_counts())\n","train_df.reset_index(drop=True, inplace=True)"],"metadata":{"id":"pu4nWNT_j98k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643287112865,"user_tz":-540,"elapsed":312,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"fc87b6c4-ee2b-4cd8-d565-98e8a8499e6e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["4    7680\n","0    5223\n","1    4030\n","3    3969\n","2    2599\n","Name: fold, dtype: int64\n","3    1540\n","1     884\n","2     876\n","0     846\n","4     773\n","Name: fold, dtype: int64\n"]}]},{"cell_type":"markdown","source":["### Get Paths"],"metadata":{"id":"EpGZBLeDiga8"}},{"cell_type":"code","source":["def get_path(row):\n","    \n","    row['image_path'] = f'{HOME_DIR}{IMAGE_DIR}/{row.image_id}.jpg'\n","    row['label_path'] = f'{HOME_DIR}{LABEL_DIR}/{row.image_id}.txt'\n","\n","    return row\n","\n","train_df = train_df.progress_apply(get_path, axis=1)"],"metadata":{"id":"1A-6Cc_bihzJ","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["a250048178ee4f5ab78afe7c532e857e","9c44d386cfcc4a4b8141856e95980447","5f05c72ced5a4f2ab9db9f18d936e95a","4b675577ca0943389d28012943436d70","8e1543a08bf04b8a8371cab5f3ea9b4e","a1db02f89ae84920a7187cee4afa5381","8888702ebdc3453ba213c0ba9fe8f717","830814b0789c45728f0c10130bf95c1a","a896926b99b44ad8be01e70b3c2eba4d","df5298b4cf234f069fbf92343ea097ee","80b6a2457ae847cc836a562dc63753d5"]},"executionInfo":{"status":"ok","timestamp":1643287116932,"user_tz":-540,"elapsed":4071,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"08f6cb3e-ccc1-4021-a843-e48c17d7d24b"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a250048178ee4f5ab78afe7c532e857e","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/4919 [00:00<?, ?it/s]"]},"metadata":{}}]},{"cell_type":"markdown","source":["### Copy "],"metadata":{"id":"dOlp5s6hh4Sc"}},{"cell_type":"code","source":["%%time\n","\n","for i in tqdm(range(len(train_df))):\n","    row = train_df.loc[i]\n","    copyfile(f'{row.old_image_path}', f'{HOME_DIR}{IMAGE_DIR}/{row.image_id}.jpg')\n","    \n","print(f'Number of files: {len(os.listdir(f\"{HOME_DIR}{IMAGE_DIR}/\"))}')"],"metadata":{"id":"j4e_LeMth36l","colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["6963e3e6e6f84fcf9deea4526a25f84a","557d50c4a3894af9aca72314d4cdc3d8","13b7c37af3fe47d1811866c997a28296","132e3655d32e42a2bc4fb85d0f8fd7f3","462976da66534c82b88dc06652609e9d","567d03cdd1a94c79aa3cc24b1ec6248d","5d82545819d8439486415f72f446af68","74b4397eabca4260bc89b00859af90f4","b722e1ee192241408423bb4b69d16bbe","3c164cfe0f1b408d9bed1831fb5d952b","7e24de8c3a624ec1be5f8d144f863446"]},"executionInfo":{"status":"ok","timestamp":1643287141939,"user_tz":-540,"elapsed":25010,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"890de761-10e1-4f76-f663-c30792165f9e"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6963e3e6e6f84fcf9deea4526a25f84a","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/4919 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Number of files: 4919\n","CPU times: user 2.99 s, sys: 4.63 s, total: 7.63 s\n","Wall time: 24.8 s\n"]}]},{"cell_type":"markdown","source":["### Create labels"],"metadata":{"id":"QdkcKoEj6_Ri"}},{"cell_type":"code","source":["cnt = 0\n","all_bboxes = []\n","\n","for row_idx in tqdm(range(train_df.shape[0])):\n","    row = train_df.iloc[row_idx]\n","    image_height = row.height\n","    image_width  = row.width\n","    bboxes_coco  = np.array(row.bboxes).astype(np.float32).copy()\n","    num_bbox     = len(bboxes_coco)\n","    names        = ['cots']*num_bbox\n","    labels       = [0]*num_bbox\n","    ## Create Annotation(YOLO)\n","    with open(row.label_path, 'w') as f:\n","        if num_bbox<1:\n","            annot = ''\n","            f.write(annot)\n","            cnt+=1\n","            continue\n","        bboxes_yolo  = coco2yolo(image_height, image_width, bboxes_coco)\n","        bboxes_yolo  = np.clip(bboxes_yolo, 0, 1)\n","        all_bboxes.extend(bboxes_yolo)\n","        for bbox_idx in range(len(bboxes_yolo)):\n","            annot = [str(labels[bbox_idx])]+ list(bboxes_yolo[bbox_idx].astype(str))+(['\\n'] if num_bbox!=(bbox_idx+1) else [''])\n","            annot = ' '.join(annot)\n","            annot = annot.strip(' ')\n","            f.write(annot)\n","            \n","print('Missing:',cnt)"],"metadata":{"id":"UbQ_xCLR7CIr","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["346d84da3ce3410fa739381445b3504d","ed7cdc2c06fb40dca5813fdd6999bbc6","949bad847672436eb7d12d7ddc23c68e","765bcefc4af842b3b2154f6c91917ffc","fff2693c2f724939b54921047e897e60","64128eb117854d2890327de0a76d9c7a","24ed95e99a80420eb956c0b171d439b0","70f8039a836a42be883f615bd7f09e04","2ecb75f2b7864f4ba9ab711124cb51cd","b5246c86aebb4cb1a50905ec834af9e2","09f52573ecbf489089354b32b8aac826"]},"executionInfo":{"status":"ok","timestamp":1643287143988,"user_tz":-540,"elapsed":2065,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"ab0f7e7e-453b-42c7-b9d9-506ae48f0acd"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"346d84da3ce3410fa739381445b3504d","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/4919 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Missing: 0\n"]}]},{"cell_type":"markdown","source":["### Configuration"],"metadata":{"id":"jadWiy31A5Zf"}},{"cell_type":"code","source":["%%time\n","import yaml\n","\n","cwd = '/content/'\n","\n","# case that use .2 split data \n","#train_only_df = train_df[train_df.is_train==True]\n","#valid_only_df = train_df[train_df.is_train==False]\n","\n","# case that use fold5 split data \n","train_only_df = train_df[train_df.fold!=FOLD]\n","valid_only_df = train_df[train_df.fold==FOLD]\n","\n","with open(os.path.join(cwd, 'train.txt'), 'w') as f:\n","    for path in train_only_df.image_path.tolist():\n","        f.write(path+'\\n')\n","\n","with open(os.path.join(cwd, 'val.txt'), 'w') as f:\n","    for path in valid_only_df.image_path.tolist():\n","        f.write(path+'\\n')\n","\n","data = dict(\n","    path = '/content/',\n","    train = os.path.join(cwd, 'train.txt'),\n","    val = os.path.join(cwd, 'val.txt'),\n","    nc = 1,\n","    names = ['cots'],\n",")\n","\n","with open(os.path.join(cwd, 'cots.yaml'), 'w') as outfile:\n","    yaml.dump(data, outfile, default_flow_style=False)\n","\n","f = open(os.path.join(cwd, 'cots.yaml'), 'r')\n","\n","print('\\nyaml')\n","print(f.read())"],"metadata":{"id":"N3nuRzF9kniE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643287144421,"user_tz":-540,"elapsed":437,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"2ae57fa7-b79b-4beb-e1dc-6729ce3f9f29"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","yaml\n","names:\n","- cots\n","nc: 1\n","path: /content/\n","train: /content/train.txt\n","val: /content/val.txt\n","\n","CPU times: user 25.8 ms, sys: 4.04 ms, total: 29.8 ms\n","Wall time: 97.3 ms\n"]}]},{"cell_type":"markdown","source":["## hyper parameter"],"metadata":{"id":"uu6hPG2UILgY"}},{"cell_type":"code","source":["data = dict(\n","    lr0 = 0.01,  # initial learning rate (SGD=1E-2, Adam=1E-3)\n","    lrf = 0.1,  # final OneCycleLR learning rate (lr0 * lrf)\n","    momentum = 0.937,  # SGD momentum/Adam beta1\n","    weight_decay = 0.0005,  # optimizer weight decay 5e-4\n","    warmup_epochs = 2.0,  # warmup epochs (fractions ok)\n","    warmup_momentum = 0.8,  # warmup initial momentum\n","    warmup_bias_lr = 0.1,  # warmup initial bias lr\n","    box = 0.05,  # box loss gain\n","    cls = 0.3,  # cls loss gain\n","    cls_pw = 1.0,  # cls BCELoss positive_weight\n","    obj = 0.7,  # obj loss gain (scale with pixels)\n","    obj_pw = 1.0,  # obj BCELoss positive_weight\n","    iou_t = 0.20,  # IoU training threshold\n","    anchor_t = 4.0,  # anchor-multiple threshold\n","    # anchors = 3,  # anchors per output layer (0 to ignore)\n","    fl_gamma = 0.0,  # focal loss gamma (efficientDet default gamma=1.5)\n","    hsv_h = 0.015,  # image HSV-Hue augmentation (fraction)\n","    hsv_s = 0.7,  # image HSV-Saturation augmentation (fraction)\n","    hsv_v = 0.4,  # image HSV-Value augmentation (fraction)\n","    degrees = 0.0,  # image rotation (+/- deg)\n","    translate = 0.1,  # image translation (+/- fraction)\n","    scale = 0.9,  # image scale (+/- gain)\n","    shear = 0.0,  # image shear (+/- deg)\n","    perspective = 0.0,  # image perspective (+/- fraction), range 0-0.001\n","    flipud = 0.5,  # image flip up-down (probability)\n","    fliplr = 0.5,  # image flip left-right (probability)\n","    mosaic = 1.0,  # image mosaic (probability)\n","    mixup = 0.6,  # image mixup (probability)\n","    copy_paste = 0.4,  # segment copy-paste (probability)\n",")\n","\n","with open(os.path.join(cwd, 'my_hyp.yaml'), 'w') as outfile:\n","    yaml.dump(data, outfile, default_flow_style=False)\n","\n","f = open(os.path.join(cwd, 'my_hyp.yaml'), 'r')\n","\n","print('\\nyaml')\n","print(f.read())"],"metadata":{"id":"XWVTWAewIN2x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643287144421,"user_tz":-540,"elapsed":6,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"e0724425-fa20-45d8-90d1-56e7eb19f063"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","yaml\n","anchor_t: 4.0\n","box: 0.05\n","cls: 0.3\n","cls_pw: 1.0\n","copy_paste: 0.4\n","degrees: 0.0\n","fl_gamma: 0.0\n","fliplr: 0.5\n","flipud: 0.5\n","hsv_h: 0.015\n","hsv_s: 0.7\n","hsv_v: 0.4\n","iou_t: 0.2\n","lr0: 0.01\n","lrf: 0.1\n","mixup: 0.6\n","momentum: 0.937\n","mosaic: 1.0\n","obj: 0.7\n","obj_pw: 1.0\n","perspective: 0.0\n","scale: 0.9\n","shear: 0.0\n","translate: 0.1\n","warmup_bias_lr: 0.1\n","warmup_epochs: 2.0\n","warmup_momentum: 0.8\n","weight_decay: 0.0005\n","\n"]}]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"xcmbVrz296fl"}},{"cell_type":"code","source":["%cd yolov5\n","\n","from yolov5 import utils\n","display = utils.notebook_init()  # check"],"metadata":{"id":"nEBV0Nsm5LSH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643287144727,"user_tz":-540,"elapsed":310,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"b48ada4c-05e5-402d-da69-f4cb24606b78"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["YOLOv5 🚀 v6.0-159-gdb6ec66 torch 1.10.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n"]},{"output_type":"stream","name":"stdout","text":["Setup complete ✅ (4 CPUs, 25.5 GB RAM, 73.5/166.8 GB disk)\n"]}]},{"cell_type":"code","source":["!python train.py --img 2624 \\\n","--batch 4 \\\n","--epochs 20 \\\n","--data /content/cots.yaml \\\n","--hyp /content/my_hyp.yaml \\\n","--weights yolov5s6.pt \\\n","--patience=5 \\\n","--workers 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xl20_lwu4FOO","outputId":"27670f6d-c030-4164-e30c-b648288ed7b0","executionInfo":{"status":"ok","timestamp":1643334578131,"user_tz":-540,"elapsed":47433408,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s6.pt, cfg=, data=/content/cots.yaml, hyp=/content/my_hyp.yaml, epochs=20, batch_size=4, imgsz=2624, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=0, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=5, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","remote: Enumerating objects: 415, done.\u001b[K\n","remote: Counting objects: 100% (175/175), done.\u001b[K\n","remote: Compressing objects: 100% (2/2), done.\u001b[K\n","remote: Total 415 (delta 173), reused 173 (delta 173), pack-reused 240\u001b[K\n","Receiving objects: 100% (415/415), 304.73 KiB | 12.70 MiB/s, done.\n","Resolving deltas: 100% (289/289), completed with 54 local objects.\n","From https://github.com/ultralytics/yolov5\n","   db6ec66..856d4e5  master              -> origin/master\n","   14de9c4..46a2a70  classifier          -> origin/classifier\n"," * [new branch]      feature/log_results -> origin/feature/log_results\n","   20c64ff..487a014  tests/aws           -> origin/tests/aws\n"," * [new branch]      updates/benchmarks  -> origin/updates/benchmarks\n","\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 57 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n","YOLOv5 🚀 v6.0-159-gdb6ec66 torch 1.10.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0manchor_t=4.0, box=0.05, cls=0.3, cls_pw=1.0, copy_paste=0.4, degrees=0.0, fl_gamma=0.0, fliplr=0.5, flipud=0.5, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, iou_t=0.2, lr0=0.01, lrf=0.1, mixup=0.6, momentum=0.937, mosaic=1.0, obj=0.7, obj_pw=1.0, perspective=0.0, scale=0.9, shear=0.0, translate=0.1, warmup_bias_lr=0.1, warmup_epochs=2.0, warmup_momentum=0.8, weight_decay=0.0005\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s6.pt to yolov5s6.pt...\n","100% 24.5M/24.5M [00:00<00:00, 142MB/s]\n","\n","Overriding model.yaml nc=80 with nc=1\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1    885504  models.common.Conv                      [256, 384, 3, 2]              \n","  8                -1  1    665856  models.common.C3                        [384, 384, 1]                 \n","  9                -1  1   1770496  models.common.Conv                      [384, 512, 3, 2]              \n"," 10                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n"," 11                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 12                -1  1    197376  models.common.Conv                      [512, 384, 1, 1]              \n"," 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n"," 15                -1  1    813312  models.common.C3                        [768, 384, 1, False]          \n"," 16                -1  1     98816  models.common.Conv                      [384, 256, 1, 1]              \n"," 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 19                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 20                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 24                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n"," 26                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 27                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n"," 29                -1  1    715008  models.common.C3                        [512, 384, 1, False]          \n"," 30                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n"," 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n"," 32                -1  1   1313792  models.common.C3                        [768, 512, 1, False]          \n"," 33  [23, 26, 29, 32]  1     23112  models.yolo.Detect                      [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [128, 256, 384, 512]]\n","Model Summary: 355 layers, 12322312 parameters, 12322312 gradients, 16.2 GFLOPs\n","\n","Transferred 451/459 items from yolov5s6.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 75 weight, 79 weight (no decay), 79 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/train' images and labels...4043 found, 0 missing, 0 empty, 0 corrupted: 100% 4043/4043 [00:00<00:00, 4801.51it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/val' images and labels...876 found, 0 missing, 0 empty, 0 corrupted: 100% 876/876 [00:00<00:00, 4623.85it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/val.cache\n","Plotting labels to runs/train/exp/labels.jpg... \n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m6.49 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Image sizes 2624 train, 2624 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns/train/exp\u001b[0m\n","Starting training for 20 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      0/19     12.6G   0.07533   0.06186         0        30      2624: 100% 1011/1011 [1:00:05<00:00,  3.57s/it]\n","               Class     Images     Labels          P          R     mAP@.5  mAP@.3:.8: 100% 110/110 [01:14<00:00,  1.47it/s]\n","                 all        876       1395      0.163      0.187      0.086     0.0353\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      1/19     13.2G   0.05579   0.04741         0        33      2624: 100% 1011/1011 [59:56<00:00,  3.56s/it]\n","               Class     Images     Labels          P          R     mAP@.5  mAP@.3:.8: 100% 110/110 [01:14<00:00,  1.48it/s]\n","                 all        876       1395      0.567      0.495      0.497      0.374\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      2/19     13.2G   0.04893   0.04287         0        47      2624: 100% 1011/1011 [59:43<00:00,  3.54s/it]\n","               Class     Images     Labels          P          R     mAP@.5  mAP@.3:.8: 100% 110/110 [01:14<00:00,  1.48it/s]\n","                 all        876       1395       0.86      0.622      0.726       0.55\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      3/19     13.2G    0.0454   0.04042         0        26      2624: 100% 1011/1011 [1:00:02<00:00,  3.56s/it]\n","               Class     Images     Labels          P          R     mAP@.5  mAP@.3:.8: 100% 110/110 [01:15<00:00,  1.46it/s]\n","                 all        876       1395       0.87      0.659      0.762      0.593\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      4/19     13.2G     0.043   0.03884         0        36      2624: 100% 1011/1011 [59:40<00:00,  3.54s/it]\n","               Class     Images     Labels          P          R     mAP@.5  mAP@.3:.8: 100% 110/110 [01:13<00:00,  1.49it/s]\n","                 all        876       1395      0.905      0.726      0.819      0.645\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      5/19     13.2G    0.0417   0.03784         0        28      2624: 100% 1011/1011 [59:32<00:00,  3.53s/it]\n","               Class     Images     Labels          P          R     mAP@.5  mAP@.3:.8: 100% 110/110 [01:13<00:00,  1.49it/s]\n","                 all        876       1395      0.875      0.709      0.795      0.636\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      6/19     13.2G   0.04017   0.03656         0        18      2624: 100% 1011/1011 [59:13<00:00,  3.51s/it]\n","               Class     Images     Labels          P          R     mAP@.5  mAP@.3:.8: 100% 110/110 [01:11<00:00,  1.54it/s]\n","                 all        876       1395      0.908      0.662      0.751      0.607\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      7/19     13.2G   0.03954   0.03638         0        38      2624: 100% 1011/1011 [59:04<00:00,  3.51s/it]\n","               Class     Images     Labels          P          R     mAP@.5  mAP@.3:.8: 100% 110/110 [01:12<00:00,  1.53it/s]\n","                 all        876       1395      0.895      0.739      0.836      0.675\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      8/19     13.2G   0.03874    0.0352         0        14      2624: 100% 1011/1011 [59:03<00:00,  3.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5  mAP@.3:.8: 100% 110/110 [01:12<00:00,  1.52it/s]\n","                 all        876       1395      0.911      0.733      0.815      0.657\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      9/19     13.2G   0.03825   0.03431         0         4      2624: 100% 1011/1011 [58:45<00:00,  3.49s/it]\n","               Class     Images     Labels          P          R     mAP@.5  mAP@.3:.8: 100% 110/110 [01:12<00:00,  1.53it/s]\n","                 all        876       1395      0.884      0.728      0.792      0.659\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     10/19     13.2G   0.03756   0.03563         0        26      2624: 100% 1011/1011 [59:11<00:00,  3.51s/it]\n","               Class     Images     Labels          P          R     mAP@.5  mAP@.3:.8: 100% 110/110 [01:12<00:00,  1.51it/s]\n","                 all        876       1395      0.897      0.732      0.798       0.63\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     11/19     13.2G   0.03694   0.03474         0        24      2624: 100% 1011/1011 [59:04<00:00,  3.51s/it]\n","               Class     Images     Labels          P          R     mAP@.5  mAP@.3:.8: 100% 110/110 [01:11<00:00,  1.53it/s]\n","                 all        876       1395      0.909       0.73      0.816      0.652\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     12/19     13.2G   0.03621   0.03412         0        39      2624: 100% 1011/1011 [59:07<00:00,  3.51s/it]\n","               Class     Images     Labels          P          R     mAP@.5  mAP@.3:.8: 100% 110/110 [01:12<00:00,  1.52it/s]\n","                 all        876       1395       0.89      0.747      0.812      0.657\n","Stopping training early as no improvement observed in last 5 epochs. Best results observed at epoch 7, best model saved as best.pt.\n","To update EarlyStopping(patience=5) pass a new patience value, i.e. `python train.py --patience 300` or use `--patience 0` to disable EarlyStopping.\n","\n","13 epochs completed in 13.142 hours.\n","Optimizer stripped from runs/train/exp/weights/last.pt, 27.0MB\n","Optimizer stripped from runs/train/exp/weights/best.pt, 27.0MB\n","\n","Validating runs/train/exp/weights/best.pt...\n","Fusing layers... \n","Model Summary: 280 layers, 12308200 parameters, 0 gradients, 16.2 GFLOPs\n","               Class     Images     Labels          P          R     mAP@.5  mAP@.3:.8: 100% 110/110 [01:20<00:00,  1.37it/s]\n","                 all        876       1395      0.895      0.739      0.836      0.675\n","Results saved to \u001b[1mruns/train/exp\u001b[0m\n"]}]},{"cell_type":"markdown","source":["#### remove val folder"],"metadata":{"id":"pJOJkUGbbz90"}},{"cell_type":"code","source":["!rm -r /content/yolov5/runs/val"],"metadata":{"id":"5ZsOJcMtbpUF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calc_f2(R, P):\n","    return (5 * P * R) / ((4*P) + R)\n","\n","R = 0.616\n","P = 0.844\n","\n","F2_score = calc_f2(R, P)\n","print(F2_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qauYhmvPcWYy","executionInfo":{"status":"ok","timestamp":1641876250573,"user_tz":-540,"elapsed":799,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"04135b55-ee4b-478e-90aa-435129084d99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.6511823647294588\n"]}]},{"cell_type":"markdown","source":["### Calculate F2 score on validation set"],"metadata":{"id":"KEPFKoYfGNXi"}},{"cell_type":"code","source":["val_conf_thres = 0.20\n","val_iou_thres = 0.30"],"metadata":{"id":"7Loa2BbVRiB0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import val\n","# /content/yolov5/runs/train/exp/weights/best.pt\n","# /content/drive/MyDrive/Colab/Great-Barrier-Reef/model/yolov5/ver12/exp/weights/best.pt\n","!python val.py --data /content/cots.yaml \\\n","    --weights /content/yolov5/runs/train/exp/weights/best.pt \\\n","    --imgsz 3200 \\\n","    --conf-thres 0.20 \\\n","    --iou-thres 0.30 \\\n","    --save-txt \\\n","    --save-conf \\\n","    --exist-ok"],"metadata":{"id":"yZP9hTzRGS4C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642777836296,"user_tz":-540,"elapsed":15484,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"5fcebb5c-b975-4beb-847b-6e26e066c5a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mdata=/content/cots.yaml, weights=['/content/yolov5/runs/train/exp/weights/best.pt'], batch_size=32, imgsz=3200, conf_thres=0.2, iou_thres=0.3, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=runs/val, name=exp, exist_ok=True, half=False, dnn=False\n","WARNING: confidence threshold 0.2 >> 0.001 will produce invalid mAP values.\n","YOLOv5 🚀 v6.0-159-gdb6ec66 torch 1.10.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n","\n","Fusing layers... \n","Model Summary: 378 layers, 35248920 parameters, 0 gradients, 49.0 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/val.cache' images and labels... 773 found, 0 missing, 0 empty, 0 corrupted: 100% 773/773 [00:00<?, ?it/s]\n","               Class     Images     Labels          P          R     mAP@.5  mAP@.3:.8:   0% 0/25 [00:08<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"val.py\", line 372, in <module>\n","    main(opt)\n","  File \"val.py\", line 345, in main\n","    run(**vars(opt))\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"val.py\", line 182, in run\n","    out, train_out = model(im) if training else model(im, augment=augment, val=True)  # inference, loss outputs\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/yolov5/models/common.py\", line 384, in forward\n","    y = self.model(im) if self.jit else self.model(im, augment=augment, visualize=visualize)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/yolov5/models/yolo.py\", line 126, in forward\n","    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n","  File \"/content/yolov5/models/yolo.py\", line 149, in _forward_once\n","    x = m(x)  # run\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/yolov5/models/common.py\", line 49, in forward_fuse\n","    return self.act(self.conv(x))\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 446, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 443, in _conv_forward\n","    self.padding, self.dilation, self.groups)\n","RuntimeError: CUDA out of memory. Tried to allocate 4.33 GiB (GPU 0; 15.90 GiB total capacity; 10.97 GiB already allocated; 3.42 GiB free; 11.47 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"]}]},{"cell_type":"markdown","source":["#### Check how predicted bounding box is created"],"metadata":{"id":"pKRAZ60BONwJ"}},{"cell_type":"code","source":["# val bbox result directory\n","PRD_BBOX_DIR = '/content/yolov5/runs/val/exp/labels/'\n","print(f'made bounding box of {len(os.listdir(PRD_BBOX_DIR))} images in validation set ')"],"metadata":{"id":"oVdLEuCXOB_y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642777836297,"user_tz":-540,"elapsed":20,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"b9e2641b-d27b-4d1f-f3e9-713f98a55bcc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["made bounding box of 0 images in validation set \n"]}]},{"cell_type":"code","source":["val_images = []\n","with open('/content/val.txt', 'r') as f:\n","    while True:\n","        r = f.readline().rstrip()\n","        if not r:\n","            break\n","        val_images.append(os.path.basename(r))\n","print(f'{len(val_images)} image in validation set')"],"metadata":{"id":"TOgdBq7vOLHK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642777836297,"user_tz":-540,"elapsed":18,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"684b7dea-101a-4fc3-cba9-81ffa883b4dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["773 image in validation set\n"]}]},{"cell_type":"code","source":["not_processed_images = val_images.copy()\n","for file in os.listdir(PRD_BBOX_DIR):\n","    img_name = file[:-4]+'.jpg'\n","    if img_name in val_images:\n","        not_processed_images.remove(img_name)\n","print(f\"yolov5 model doesn't create bounding box for {len(not_processed_images)} images\")"],"metadata":{"id":"ekgy6uQUOYZy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642777836297,"user_tz":-540,"elapsed":16,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"adfa9413-0b0d-4c29-e492-03f9e0eed8de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["yolov5 model doesn't create bounding box for 773 images\n"]}]},{"cell_type":"code","source":["# model didn't detect starfish in \"not_processed_images\" - it will be calculated as False Negative(FN)\n","# run code to know that there exist ground truth bounding boxs in \"not_processed_images\"\n","# in fact, /kaggle/images/ only include images which have bounding boxs\n","for image_name in not_processed_images[:20]:\n","    img = cv2.imread('/content/dataset/images/'+image_name)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    #plt.imshow(img)\n","    #plt.title(image_name)\n","    #plt.show()\n","    txt_name = image_name[:-4]+'.txt'\n","    with open('/content/dataset/labels/'+txt_name, 'r') as f:\n","        r = f.read()\n","        count = r.count('\\n')+1\n","        print(f\"{image_name} has {count} ground truth bounding box exits\")"],"metadata":{"id":"FiP0ewaNOchG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642777836835,"user_tz":-540,"elapsed":551,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"707cce8e-2c61-488c-b836-bc1b981c436e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0-16.jpg has 1 ground truth bounding box exits\n","0-17.jpg has 1 ground truth bounding box exits\n","0-18.jpg has 1 ground truth bounding box exits\n","0-19.jpg has 1 ground truth bounding box exits\n","0-20.jpg has 1 ground truth bounding box exits\n","0-21.jpg has 1 ground truth bounding box exits\n","0-22.jpg has 1 ground truth bounding box exits\n","0-23.jpg has 1 ground truth bounding box exits\n","0-24.jpg has 1 ground truth bounding box exits\n","0-25.jpg has 1 ground truth bounding box exits\n","0-26.jpg has 1 ground truth bounding box exits\n","0-27.jpg has 1 ground truth bounding box exits\n","0-28.jpg has 1 ground truth bounding box exits\n","0-29.jpg has 1 ground truth bounding box exits\n","0-30.jpg has 1 ground truth bounding box exits\n","0-31.jpg has 1 ground truth bounding box exits\n","0-32.jpg has 1 ground truth bounding box exits\n","0-33.jpg has 1 ground truth bounding box exits\n","0-34.jpg has 1 ground truth bounding box exits\n","0-35.jpg has 2 ground truth bounding box exits\n"]}]},{"cell_type":"code","source":["def calc_iou(bboxes1, bboxes2, bbox_mode='xywh'):\n","    assert len(bboxes1.shape) == 2 and bboxes1.shape[1] == 4\n","    assert len(bboxes2.shape) == 2 and bboxes2.shape[1] == 4\n","    \n","    bboxes1 = bboxes1.copy()\n","    bboxes2 = bboxes2.copy()\n","    \n","    if bbox_mode == 'xywh':\n","        bboxes1[:, 2:] += bboxes1[:, :2]\n","        bboxes2[:, 2:] += bboxes2[:, :2]\n","\n","    x11, y11, x12, y12 = np.split(bboxes1, 4, axis=1)\n","    x21, y21, x22, y22 = np.split(bboxes2, 4, axis=1)\n","    xA = np.maximum(x11, np.transpose(x21))\n","    yA = np.maximum(y11, np.transpose(y21))\n","    xB = np.minimum(x12, np.transpose(x22))\n","    yB = np.minimum(y12, np.transpose(y22))\n","    interArea = np.maximum((xB - xA + 1), 0) * np.maximum((yB - yA + 1), 0)\n","    boxAArea = (x12 - x11 + 1) * (y12 - y11 + 1)\n","    boxBArea = (x22 - x21 + 1) * (y22 - y21 + 1)\n","    iou = interArea / (boxAArea + np.transpose(boxBArea) - interArea)\n","    return iou\n","\n","def f_beta(tp, fp, fn, beta=2):\n","    return (1+beta**2)*tp / ((1+beta**2)*tp + beta**2*fn+fp)\n","\n","def calc_is_correct_at_iou_th(gt_bboxes, pred_bboxes, iou_th, verbose=False):\n","    gt_bboxes = gt_bboxes.copy()\n","    pred_bboxes = pred_bboxes.copy()\n","    \n","    tp = 0\n","    fp = 0\n","    for k, pred_bbox in enumerate(pred_bboxes): # fixed in ver.7\n","        ious = calc_iou(gt_bboxes, pred_bbox[None, 1:])\n","        max_iou = ious.max()\n","        if max_iou > iou_th:\n","            tp += 1\n","            gt_bboxes = np.delete(gt_bboxes, ious.argmax(), axis=0)\n","        else:\n","            fp += 1\n","        if len(gt_bboxes) == 0:\n","            fp += len(pred_bboxes) - (k + 1) # fix in ver.7\n","            break\n","\n","    fn = len(gt_bboxes)\n","    return tp, fp, fn\n","\n","def calc_is_correct(gt_bboxes, pred_bboxes):\n","    \"\"\"\n","    gt_bboxes: (N, 4) np.array in xywh format\n","    pred_bboxes: (N, 5) np.array in conf+xywh format\n","    \"\"\"\n","    if len(gt_bboxes) == 0 and len(pred_bboxes) == 0:\n","        tps, fps, fns = 0, 0, 0\n","        return tps, fps, fns\n","    \n","    elif len(gt_bboxes) == 0:\n","        tps, fps, fns = 0, len(pred_bboxes)*11, 0\n","        return tps, fps, fns\n","    \n","    elif len(pred_bboxes) == 0:\n","        tps, fps, fns = 0, 0, len(gt_bboxes)*11\n","        return tps, fps, fns\n","    \n","    pred_bboxes = pred_bboxes[pred_bboxes[:,0].argsort()[::-1]] # sort by conf\n","    \n","    tps, fps, fns = 0, 0, 0\n","    for iou_th in np.arange(0.3, 0.85, 0.05):\n","        tp, fp, fn = calc_is_correct_at_iou_th(gt_bboxes, pred_bboxes, iou_th)\n","        tps += tp\n","        fps += fp\n","        fns += fn\n","    return tps, fps, fns\n","\n","def calc_f2_score(gt_bboxes_list, pred_bboxes_list, verbose=False):\n","    \"\"\"\n","    gt_bboxes_list: list of (N, 4) np.array in xywh format\n","    pred_bboxes_list: list of (N, 5) np.array in conf+xywh format\n","    \"\"\"\n","    tps, fps, fns = 0, 0, 0\n","    for gt_bboxes, pred_bboxes in zip(gt_bboxes_list, pred_bboxes_list):\n","        tp, fp, fn = calc_is_correct(gt_bboxes, pred_bboxes)\n","        tps += tp\n","        fps += fp\n","        fns += fn\n","        if verbose:\n","            num_gt = len(gt_bboxes)\n","            num_pred = len(pred_bboxes)\n","            print(f'num_gt:{num_gt:<3} num_pred:{num_pred:<3} tp:{tp:<3} fp:{fp:<3} fn:{fn:<3}')\n","    return f_beta(tps, fps, fns, beta=2)"],"metadata":{"id":"dZhWaflrQoC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gt_bboxs_list, prd_bboxs_list = [], []\n","count = 0\n","for image_file in val_images:\n","    txt_name = image_file[:-4]+'.txt'\n","    gt_bboxs = []\n","    prd_bboxs = []\n","    with open('/content/'+LABEL_DIR+'/'+txt_name, 'r') as f:\n","        while True:\n","            r = f.readline().rstrip()\n","            if not r:\n","                break\n","            r = r.split()[1:]\n","            bbox = np.array(list(map(float, r)))\n","            gt_bboxs.append(bbox)\n","    if os.path.exists(PRD_BBOX_DIR+txt_name):\n","        with open(PRD_BBOX_DIR+txt_name, 'r') as f:\n","            while True:\n","                r = f.readline().rstrip()\n","                if not r:\n","                    break\n","                r = r.split()[1:]\n","                r = [r[4], *r[:4]]\n","                bbox = np.array(list(map(float, r)))\n","                prd_bboxs.append(bbox)\n","    gt_bboxs, prd_bboxs = np.array(gt_bboxs), np.array(prd_bboxs)\n","    gt_bboxs_list.append(gt_bboxs)\n","    prd_bboxs_list.append(prd_bboxs)\n","    count += 1\n","print(f'{count} bound boxs appended to list')"],"metadata":{"id":"dZWDQAhcQqzb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642777836836,"user_tz":-540,"elapsed":18,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"bf000d1a-3146-43aa-9803-8ac34f8e6a23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["773 bound boxs appended to list\n"]}]},{"cell_type":"code","source":["score = calc_f2_score(gt_bboxs_list, prd_bboxs_list, verbose=True)"],"metadata":{"id":"60GAgcHcQ4QU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642777836837,"user_tz":-540,"elapsed":14,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"dff7e43f-5ff3-4218-ec48-529345f350a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:5   num_pred:0   tp:0   fp:0   fn:55 \n","num_gt:5   num_pred:0   tp:0   fp:0   fn:55 \n","num_gt:4   num_pred:0   tp:0   fp:0   fn:44 \n","num_gt:4   num_pred:0   tp:0   fp:0   fn:44 \n","num_gt:4   num_pred:0   tp:0   fp:0   fn:44 \n","num_gt:4   num_pred:0   tp:0   fp:0   fn:44 \n","num_gt:4   num_pred:0   tp:0   fp:0   fn:44 \n","num_gt:5   num_pred:0   tp:0   fp:0   fn:55 \n","num_gt:5   num_pred:0   tp:0   fp:0   fn:55 \n","num_gt:6   num_pred:0   tp:0   fp:0   fn:66 \n","num_gt:7   num_pred:0   tp:0   fp:0   fn:77 \n","num_gt:7   num_pred:0   tp:0   fp:0   fn:77 \n","num_gt:7   num_pred:0   tp:0   fp:0   fn:77 \n","num_gt:7   num_pred:0   tp:0   fp:0   fn:77 \n","num_gt:8   num_pred:0   tp:0   fp:0   fn:88 \n","num_gt:8   num_pred:0   tp:0   fp:0   fn:88 \n","num_gt:9   num_pred:0   tp:0   fp:0   fn:99 \n","num_gt:10  num_pred:0   tp:0   fp:0   fn:110\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:12  num_pred:0   tp:0   fp:0   fn:132\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:12  num_pred:0   tp:0   fp:0   fn:132\n","num_gt:12  num_pred:0   tp:0   fp:0   fn:132\n","num_gt:12  num_pred:0   tp:0   fp:0   fn:132\n","num_gt:12  num_pred:0   tp:0   fp:0   fn:132\n","num_gt:12  num_pred:0   tp:0   fp:0   fn:132\n","num_gt:12  num_pred:0   tp:0   fp:0   fn:132\n","num_gt:12  num_pred:0   tp:0   fp:0   fn:132\n","num_gt:13  num_pred:0   tp:0   fp:0   fn:143\n","num_gt:13  num_pred:0   tp:0   fp:0   fn:143\n","num_gt:13  num_pred:0   tp:0   fp:0   fn:143\n","num_gt:13  num_pred:0   tp:0   fp:0   fn:143\n","num_gt:13  num_pred:0   tp:0   fp:0   fn:143\n","num_gt:13  num_pred:0   tp:0   fp:0   fn:143\n","num_gt:13  num_pred:0   tp:0   fp:0   fn:143\n","num_gt:13  num_pred:0   tp:0   fp:0   fn:143\n","num_gt:13  num_pred:0   tp:0   fp:0   fn:143\n","num_gt:13  num_pred:0   tp:0   fp:0   fn:143\n","num_gt:13  num_pred:0   tp:0   fp:0   fn:143\n","num_gt:13  num_pred:0   tp:0   fp:0   fn:143\n","num_gt:13  num_pred:0   tp:0   fp:0   fn:143\n","num_gt:13  num_pred:0   tp:0   fp:0   fn:143\n","num_gt:12  num_pred:0   tp:0   fp:0   fn:132\n","num_gt:12  num_pred:0   tp:0   fp:0   fn:132\n","num_gt:12  num_pred:0   tp:0   fp:0   fn:132\n","num_gt:12  num_pred:0   tp:0   fp:0   fn:132\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:11  num_pred:0   tp:0   fp:0   fn:121\n","num_gt:10  num_pred:0   tp:0   fp:0   fn:110\n","num_gt:10  num_pred:0   tp:0   fp:0   fn:110\n","num_gt:10  num_pred:0   tp:0   fp:0   fn:110\n","num_gt:10  num_pred:0   tp:0   fp:0   fn:110\n","num_gt:10  num_pred:0   tp:0   fp:0   fn:110\n","num_gt:10  num_pred:0   tp:0   fp:0   fn:110\n","num_gt:10  num_pred:0   tp:0   fp:0   fn:110\n","num_gt:10  num_pred:0   tp:0   fp:0   fn:110\n","num_gt:9   num_pred:0   tp:0   fp:0   fn:99 \n","num_gt:9   num_pred:0   tp:0   fp:0   fn:99 \n","num_gt:8   num_pred:0   tp:0   fp:0   fn:88 \n","num_gt:8   num_pred:0   tp:0   fp:0   fn:88 \n","num_gt:7   num_pred:0   tp:0   fp:0   fn:77 \n","num_gt:6   num_pred:0   tp:0   fp:0   fn:66 \n","num_gt:6   num_pred:0   tp:0   fp:0   fn:66 \n","num_gt:6   num_pred:0   tp:0   fp:0   fn:66 \n","num_gt:6   num_pred:0   tp:0   fp:0   fn:66 \n","num_gt:6   num_pred:0   tp:0   fp:0   fn:66 \n","num_gt:6   num_pred:0   tp:0   fp:0   fn:66 \n","num_gt:4   num_pred:0   tp:0   fp:0   fn:44 \n","num_gt:4   num_pred:0   tp:0   fp:0   fn:44 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:3   num_pred:0   tp:0   fp:0   fn:33 \n","num_gt:2   num_pred:0   tp:0   fp:0   fn:22 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n","num_gt:1   num_pred:0   tp:0   fp:0   fn:11 \n"]}]},{"cell_type":"code","source":["print('val_conf_thres & val_iou_thres is ', val_conf_thres, val_iou_thres)\n","print(f'f2 score for validation set is {score}')"],"metadata":{"id":"1GqTS19LQ6dr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642777836837,"user_tz":-540,"elapsed":12,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}},"outputId":"1abc6d7f-8984-491e-cbf6-598a7de7e6a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["val_conf_thres & val_iou_thres is  0.2 0.3\n","f2 score for validation set is 0.0\n"]}]},{"cell_type":"markdown","source":["### Copy result"],"metadata":{"id":"dGD_QgB-GKrM"}},{"cell_type":"code","source":["!cp -r /content/yolov5/runs/train/exp /content/drive/MyDrive/Colab/Great-Barrier-Reef/model/exp"],"metadata":{"id":"sP7wAPt6z-oG","executionInfo":{"status":"ok","timestamp":1643334578693,"user_tz":-540,"elapsed":569,"user":{"displayName":"BlueLemon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVsev__2OoXWdWkqtrCytIpGYVXykJqPtEifc0bQ=s64","userId":"14634484145161271479"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"D-FpFxhk601C"},"execution_count":null,"outputs":[]}]}