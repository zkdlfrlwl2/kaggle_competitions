## A Recipe for Training Neural Networks



### Overview

1) **Neural net training is a leaky abstraction**
   * 어떻게 작동하는지 이해하지 않고 기술을 계속 사용하면 실패할 가능성이 높습니다.
2) **Neural net training fails silently**
   * 문법 or 구문 오류와 다르게 neural net의 misconfiguration은 exception이 발생하지 않고 단순히 모델 성능이 나빠질 뿐이라 찾기가 어렵다. 인내와 세심한 주의가 필요하다.



### The recipe

1. **Become one with the data**

   * 첫 번째 단계는 신경망 코드를 건드리지 않고 데이터를 철저히 검사하는 것 입니다.
2. **Set up the end-to-end training/evaluation skeleton + get dumb baselines**

   * full training & evaluation skeleton을 형성하고 일련의 실험을 통해 correctness(정확성?)에 대한 신뢰를 얻는 것 입니다. 이 단계에서는 어떻게든 망칠 수 없는 간단한 모델을 선택하는 것 - **선형 분류기 or 매우 작은 ConvNet** - 이 가장 좋습니다. 
   * 선택한 모델을 학습하고 losses, metrics, model predictions을 시각화하고 perform a series of **ablation experiments** with explicit hypotheses (명백한 가설).
   * ablation: 인공 지능(AI), 특히 기계 학습(ML)에서 제거는 AI 시스템의 구성 요소를 제거하는 것입니다. 절제 연구는 전체 시스템에 대한 구성 요소의 기여도를 이해하기 위해 특정 구성 요소를 제거하여 AI 시스템의 성능을 연구합니다.
   * Tips & tricks for this stage:
     * **fix random seed**: 코드를 두 번 실행할 때 동일한 결과를 얻을 수 있도록 항상 고정된 임의의 시드를 사용하십시오. 이렇게 하면 변동 요인이 제거되고 제정신을 유지하는 데 도움이 됩니다.
     * **simplify**: 불필요한 fanciness (공상)을 비활성화하십시오. 예를 들어 이 단계에서 모든 data augmentation을 확실히 끄십시오. 데이터 증강은 나중에 통합할 수 있는 정규화 전략이지만 지금은 멍청한 버그의 원인이 될 수 있다.
     * **add significant digits to your eval**: test loss를 plotting할 때 전체 혹은 큰 사이즈의 test set에 대해 평가를 실행합니다. batch에 대한 test loss를 plotting 한 다음 tensorboard에서 smoothing 하는데 의존하지 마십시오..
     *  **verify loss @ init**: loss 값이 올바른 loss 값에서 시작하는지 확인 합니다. 선택한 loss function의 계산값과 유사한지 비교해야 한다.
     * **init well**: final layer의 weights를 올바르게 초기화합니다. 예를 들어 평균이 50인 일부 값을 회귀하는 경우 final bias를 50으로 초기화합니다. will speed up convergence and eliminate “hockey stick” loss curves
     * **human baseline**: 사람이 해석하고 확인할 수 있는 손실 이외의 메트릭(예: 정확도)을 모니터링합니다. 가능할 때마다 자신의 (인간) 정확도를 평가하고 비교하십시오. 또는 테스트 데이터에 두 번 주석을 달고 각 예제에 대해 하나의 주석을 예측으로 처리하고 두 번째 주석을 실측으로 처리합니다.
     * **input-independent baseline**: 입력 독립적인 기준선을 훈련합니다(예: 가장 쉬운 방법은 모든 입력을 0으로 설정하는 것입니다). 이것은 데이터를 0으로 만들지 않고 실제로 연결할 때보다 성능이 더 나빠야 합니다. 즉, 모델이 입력에서 정보를 추출하는 방법을 배우나요?
     * **overfit one batch**: 모델의 용량을 늘리고(예: 레이어 또는 필터 추가) 달성 가능한 가장 낮은 손실(예: 0)에 도달할 수 있는지 확인합니다. 나는 또한 label과 prediction을 동일한 플롯에서 시각화하고 최소 손실에 도달하면 완벽하게 정렬되도록 하는 것을 좋아합니다. 그렇지 않은 경우 어딘가에 버그가 있는 것이며 다음 단계로 진행할 수 없습니다.
     * **verify decreasing training loss**: 이 단계에서 당신은 장난감 모델로 작업하고 있기 때문에 데이터셋에 과소적합될 것입니다. 용량을 조금 늘리십시오. 훈련 손실이 예상대로 줄어들었나요?
     * **visualize just before the net**: 데이터를 시각화하기 위한 명확하게 올바른 위치는 y_hat = model(x)(또는 tf의 sess.run) 바로 앞입니다. **즉, 데이터와 레이블의 원시 텐서를 시각화로 디코딩하여 네트워크에 들어가는 것을 정확히 시각화하고 싶습니다. 이것이 유일한 "진리의 근원"입니다.** 이것이 저를 구했고 데이터 전처리 및 증강의 문제를 드러낸 횟수를 셀 수 없습니다.
     * **visualize prediction dynamics**:저는 훈련 과정에서 고정된 테스트 배치에 대한 모델 예측을 시각화하는 것을 좋아합니다. 이러한 예측이 어떻게 움직이는지에 대한 "역학"은 훈련이 어떻게 진행되는지에 대한 믿을 수 없을 정도로 좋은 직관을 제공합니다. 여러 번 네트워크가 어떤 방식으로든 너무 많이 흔들려 불안정성을 드러내면 데이터에 맞추기 위해 "고투"하는 것을 느낄 수 있습니다. 매우 낮거나 매우 높은 학습률도 지터의 양에서 쉽게 알 수 있습니다.
     * **use backprop to chart dependencies**: ???
     * **generalize a special case**: ???
3. **Overfit**

   * 좋은 모델을 찾기 위해 내가 취하고 싶은 접근 방식은 두 단계로 나뉩니다. 먼저 과적합될 수 있을 만큼 충분히 큰 모델을 얻은 다음 (즉, 훈련 손실에 집중) 적절하게 정규화합니다 (검증 손실을 개선하기 위해 약간의 훈련 손실 포기). 내가 이 두 단계를 좋아하는 이유는 어떤 모델에서도 낮은 오류율에 도달할 수 없는 경우 다시 일부 문제, 버그 또는 구성 오류를 나타낼 수 있기 때문입니다.
   * Tips & tricks for this stage:
   
     * **picking the model**: 좋은 훈련 손실에 도달하려면 데이터에 적절한 아키텍처를 선택하고 싶을 것입니다. 이것을 선택할 때 제 1 조언은 다음과 같습니다. 영웅이 되지 마십시오. 나는 그들에게 의미가 있는 다양한 이국적인 아키텍처에서 신경망 도구 상자의 레고 블록을 쌓는 데 열성적이고 창의적이기를 열망하는 많은 사람들을 보았습니다. 프로젝트의 초기 단계에서 이 유혹을 강하게 물리치십시오. 나는 항상 사람들에게 **가장 관련성이 높은 논문을 찾아 좋은 성능을 달성하는 가장 간단한 아키텍처를 복사하여 붙여넣으라고 조언**합니다. 예를 들어 **이미지를 분류하는 경우** 영웅이 되지 말고 **첫 번째 실행을 위해 ResNet-50을 복사하여 붙여**넣으십시오. 나중에 더 많은 사용자 정의를 수행하고 이를 이길 수 있습니다.
     * **adam is safe**: 기준선 설정의 **초기 단계에서 저는 Adam을 학습률 3e-4로 사용하는 것**을 좋아합니다. 내 경험에 따르면 Adam은 나쁜 학습률을 포함하여 하이퍼 파라미터에 대해 훨씬 더 관대합니다. ConvNet의 경우 잘 조정된 SGD는 거의 항상 Adam을 약간 능가하지만 최적의 학습률 영역은 훨씬 더 좁고 문제에 따라 다릅니다. (참고: RNN 및 관련 시퀀스 모델을 사용하는 경우 Adam을 사용하는 것이 더 일반적입니다. 다시 프로젝트의 초기 단계에서 영웅이 되지 말고 가장 관련된 논문이 무엇이든 따르십시오)
     * **complexify only one at a time**: If you have multiple signals to plug into your classifier I would advise that you plug them in one by one and every time ensure that you get a performance boost you’d expect. (분류기에 연결할 여러 신호가 있는 경우 하나씩 연결하고 매번 예상한 성능 향상을 얻을 수 있는지 확인하는 것이 좋습니다.) 처음부터 모델에게 싱크대를 던지지 마십시오. 복잡성을 구축하는 다른 방법이 있습니다. 작은 이미지를 먼저 연결하고 나중에 크게 만드는 등의 작업을 시도할 수 있습니다.
     * **do not trust learning rate decay defaults**: **다른 도메인의 코드를 용도 변경하는 경우 학습률 감소에 항상 주의하십시오.** 다른 문제에 대해 다른 감쇠 일정을 사용하고 싶을 뿐만 아니라, 더 나쁜 것은 일반적인 구현에서 일정은 현재 에포크 번호를 기반으로 하며 이는 **단순히 데이터 세트의 크기에 따라 크게 달라질 수 있습니다.** 예를 들어 ImageNet은 epoch 30에서 10으로 감소합니다. ImageNet을 훈련하지 않는다면 거의 확실히 이것을 원하지 않을 것입니다. 주의하지 않으면 코드가 비밀리에 학습률을 너무 일찍 0으로 만들어 모델이 수렴하지 못하게 할 수 있습니다. 내 작업에서 나는 항상 학습률 감쇠를 완전히 비활성화하고(저는 상수 LR을 사용합니다) 이것을 끝까지 조정합니다.
4. **Regularize**
   * 이상적으로는 이제 최소한 훈련 세트에 맞는 큰 모델이 있는 위치에 있습니다. 이제 훈련 정확도의 일부를 포기하여 정규화하고 유효성 검사 정확도를 얻을 때입니다.
   * Some tips & tricks:
     * **get more data**: 실제 환경에서 모델을 정규화하는 가장 좋고 선호하는 방법은 실제 훈련 데이터를 더 추가하는 것입니다. 대신 더 많은 데이터를 수집할 수 있을 때 작은 데이터 세트에서 주스를 짜내려고 많은 엔지니어링 주기를 소비하는 것은 매우 흔한 실수입니다. 내가 아는 한 더 많은 데이터를 추가하는 것이 잘 구성된 신경망의 성능을 거의 무한정으로 단조롭게 향상시키는 유일한 보장된 방법입니다.
     * **data augment**: 실제 데이터 다음으로 가장 좋은 것은 가짜 데이터입니다. 보다 적극적인 데이터 증강을 시도하십시오.
     * **creative augmentation**: 반쪽짜리 데이터가 하지 못한다면 가짜 데이터도 뭔가를 할 수 있습니다. 사람들은 데이터세트를 확장하는 창의적인 방법을 찾고 있습니다. 예를 들어, 도메인 무작위화, 시뮬레이션 사용, 장면에 데이터(잠재적으로 시뮬레이션된) 삽입 또는 GAN과 같은 영리한 하이브리드.
     * **pretrain**: 데이터가 충분하더라도 가능하면 사전 훈련된 네트워크를 사용하는 것이 나쁠 일은 거의 없습니다.
     * **stick with supervised learning**: 감독되지 않은 사전 훈련에 대해 지나치게 흥분하지 마십시오. 2008년의 그 블로그 게시물이 말하는 것과는 달리, 내가 아는 한 그 어떤 버전도 현대 컴퓨터 비전에서 강력한 결과를 보고하지 않았습니다. 텍스트의 의도적인 특성 및 더 높은 신호 대 잡음비).
     * **smaller input dimensionality**: 스퓨리어스(가짜) 신호를 포함할 수 있는 기능을 제거합니다. 추가된 스퓨리어스 입력은 데이터 세트가 작은 경우 과대적합할 수 있는 또 다른 기회일 뿐입니다. 마찬가지로 낮은 수준의 세부 사항이 그다지 중요하지 않은 경우 더 작은 이미지를 입력하십시오.
     * **smaller model size**: 많은 경우 네트워크에서 도메인 지식 제약을 사용하여 크기를 줄일 수 있습니다. 예를 들어 ImageNet의 백본 상단에서 완전히 연결된 레이어를 사용하는 것이 유행이었지만 이후에는 단순한 평균 풀링으로 대체되어 프로세스에서 수많은 매개변수가 제거되었습니다.
     * **decrease the batch size**: 배치 규범 내부의 정규화로 인해 배치 크기가 작을수록 더 강한 정규화에 해당합니다. 이는 배치 경험적 평균/표준이 전체 평균/표준의 더 근사한 버전이므로 스케일 및 오프셋이 일괄 처리를 더 많이 "흔들기" 때문입니다.
     * **drop**: ConvNet에 dropout2d(공간 드롭아웃)를 사용합니다. 드롭아웃이 배치 정규화에서 제대로 작동하지 않는 것 같기 때문에 이것을 주의해서 사용하십시오.
     * **weight decay**: 가중치 감소 패널티를 높입니다.
     * **early stopping**: 측정된 유효성 검사 손실을 기반으로 훈련을 중지하여 과적합하려는 모델을 포착하십시오.
     * **try a larger model**: 나는 이것을 마지막으로 그리고 일찍 중지한 후에만 언급하지만 과거에는 더 큰 모델이 물론 결국에는 훨씬 더 과적합되지만 "조기 중지된" 성능은 종종 작은 모델의 성능보다 훨씬 더 좋을 수 있다는 것을 과거에 몇 번 발견했습니다.
   * 마지막으로, 네트워크가 합리적인 분류자라는 추가적인 확신을 얻기 위해 네트워크의 첫 번째 계층 가중치를 시각화하고 의미 있는 멋진 가장자리를 얻을 수 있도록 하고 싶습니다. 첫 번째 레이어 필터가 노이즈처럼 보인다면 문제가 있을 수 있습니다. 유사하게, 네트워크 내부의 활성화는 때때로 이상한 아티팩트를 표시하고 문제에 대한 힌트를 표시할 수 있습니다.
5. **Tune**
   * You should now be “in the loop” with your dataset exploring a wide model space for architectures that achieve low validation loss.
   * A few tips and tricks for this step:
     * **random over grid search**: 여러 하이퍼파라미터를 동시에 조정하는 경우 그리드 검색을 사용하여 모든 설정의 적용 범위를 보장하는 것이 유혹적으로 들릴 수 있지만 대신 **임의 검색을 사용하는 것이 가장 좋습니다.** 직관적으로 이것은 신경망이 종종 다른 매개변수보다 일부 매개변수에 훨씬 더 민감하기 때문입니다. 한계 내에서 매개변수가 중요하지만 b를 변경해도 효과가 없다면 몇 개의 고정된 지점에서 여러 번 샘플링하는 것보다 더 철저하게 샘플링하는 것이 좋습니다.
     * **hyper-parameter optimization**: 주변에 멋진 베이지안 하이퍼 매개변수 최적화 도구 상자가 많이 있으며 내 친구 중 일부도 이 도구를 사용하여 성공했다고 보고했습니다.
6. **Squeeze out the juice**
   * 최상의 유형의 아키텍처와 하이퍼 매개변수를 찾으면 몇 가지 트릭을 더 사용하여 시스템에서 마지막 조각을 짜낼 수 있습니다.
   * **ensembles**: 모델 앙상블은 무엇이든 2%의 정확도를 얻을 수 있는 거의 보장된 방법입니다.
   * **leave it training**: 나는 종종 사람들이 검증 손실이 평준화되는 것처럼 보일 때 모델 훈련을 중단하려는 유혹을 받는 것을 보았습니다. 내 경험에 따르면 네트워크는 직관적이지 않은 시간 동안 훈련을 계속합니다. 

​       



### Reference

* http://karpathy.github.io/2019/04/25/recipe/
* https://en.wikipedia.org/wiki/Ablation_(artificial_intelligence)

