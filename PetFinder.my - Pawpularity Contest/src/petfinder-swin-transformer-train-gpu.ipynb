{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\n\nsys.path.append(\"../input/tez-lib/\")\nsys.path.append(\"../input/timmmaster/\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-22T01:14:51.350542Z","iopub.execute_input":"2021-11-22T01:14:51.351650Z","iopub.status.idle":"2021-11-22T01:14:51.376954Z","shell.execute_reply.started":"2021-11-22T01:14:51.351512Z","shell.execute_reply":"2021-11-22T01:14:51.376170Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"import tez\nimport albumentations\nimport pandas as pd\nimport cv2\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport math\nimport random\nimport timm\nimport gc\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom tez.callbacks import EarlyStopping\nfrom tqdm import tqdm\n\nONLY_FIRST_FOLD=True","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:16:43.677816Z","iopub.execute_input":"2021-11-22T01:16:43.678103Z","iopub.status.idle":"2021-11-22T01:16:43.757722Z","shell.execute_reply.started":"2021-11-22T01:16:43.678075Z","shell.execute_reply":"2021-11-22T01:16:43.756589Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    torch.cuda.manual_seed(seed)\n    #torch.cuda.manual_seed_all(seed) # if use multi-GPU\n\n    #torch.backends.cudnn.deterministic = True\n    #torch.backends.cudnn.benchmark = False\n\nset_seed(2021)\nprint(\"set seed\")","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:15:04.653668Z","iopub.execute_input":"2021-11-22T01:15:04.653933Z","iopub.status.idle":"2021-11-22T01:15:04.666691Z","shell.execute_reply.started":"2021-11-22T01:15:04.653904Z","shell.execute_reply":"2021-11-22T01:15:04.665667Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/pet-remove-dup-ver2/train_remove_dup_10folds.csv\")\n#df = pd.read_csv(\"../input/same-old-creating-folds/train_10folds.csv\")\n\ndense_features = [\n    'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n    'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n]","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:15:04.668326Z","iopub.execute_input":"2021-11-22T01:15:04.668698Z","iopub.status.idle":"2021-11-22T01:15:04.714075Z","shell.execute_reply.started":"2021-11-22T01:15:04.668647Z","shell.execute_reply":"2021-11-22T01:15:04.713099Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class args:\n    batch_size = 4\n    image_size = 224\n    epochs = 20\n    fold = 10\n    head_out = 192\n    features = 0","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:18:49.202445Z","iopub.execute_input":"2021-11-22T00:18:49.202640Z","iopub.status.idle":"2021-11-22T00:18:49.208719Z","shell.execute_reply.started":"2021-11-22T00:18:49.202616Z","shell.execute_reply":"2021-11-22T00:18:49.207935Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def sigmoid(x):\n    return 1 / (1 + math.exp(-x))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:18:49.210487Z","iopub.execute_input":"2021-11-22T00:18:49.210770Z","iopub.status.idle":"2021-11-22T00:18:49.217296Z","shell.execute_reply.started":"2021-11-22T00:18:49.210735Z","shell.execute_reply":"2021-11-22T00:18:49.216337Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class PawpularDataset:\n    def __init__(self, image_paths, dense_features, targets, augmentations):\n        self.image_paths = image_paths\n        self.dense_features = dense_features\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        image = cv2.imread(self.image_paths[item])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n        \n        # (720, 405, 3) -> (3, 720, 405)\n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        features = self.dense_features[item, :]\n        targets = self.targets[item]\n        \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"features\": torch.tensor(features, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.float),\n        }","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:18:49.218707Z","iopub.execute_input":"2021-11-22T00:18:49.219094Z","iopub.status.idle":"2021-11-22T00:18:49.230863Z","shell.execute_reply.started":"2021-11-22T00:18:49.219055Z","shell.execute_reply":"2021-11-22T00:18:49.229954Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class PawpularModel(tez.Model):\n    def __init__(self, model_name, train=True, head_out=128, features=12):\n        super().__init__()\n        \n        self.model = timm.create_model(model_name, pretrained=train, in_chans=3)\n        self.model.head = nn.Linear(self.model.head.in_features, head_out)\n        self.dropout = nn.Dropout(0.1)\n        self.dense1 = nn.Linear(head_out+features, 64)\n        self.selu = nn.SELU()\n        self.relu = nn.ReLU()\n        self.dense2 = nn.Linear(64, 1)\n        self.dense2.bias.data = torch.nn.Parameter(\n            torch.Tensor([0.0])\n        )\n        \n        self.step_scheduler_after = \"epoch\"\n\n    def monitor_metrics(self, outputs, targets):\n        outputs = outputs.cpu().detach().numpy() #* 100.0\n        targets = targets.cpu().detach().numpy() #* 100.0\n        rmse = metrics.mean_squared_error(targets, outputs, squared=False)\n        return {\"rmse\": rmse}\n\n    def fetch_scheduler(self):\n        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n        )\n        \n        #sch = torch.optim.lr_scheduler.CosineAnnealingLR(\n        #    self.optimizer, T_max=10, eta_min=1e-6\n        #)\n        \n        return sch\n\n    def fetch_optimizer(self):\n        opt = torch.optim.Adam(self.parameters(), lr=1e-5)\n        return opt\n\n    def forward(self, image, features, targets=None):\n        \n        x = self.model(image) \n        #x = self.dropout(x1)\n        #x = torch.cat([x, features], dim=1) \n        #x = self.selu(x)\n        x = self.dense1(x) \n        #x = self.relu(x)\n        x = self.dense2(x) \n        #x = self.selu(x)\n        \n        # x = torch.cat([x, x1, features], dim=1)\n\n        if targets is not None:\n            loss = nn.MSELoss()(x, targets.view(-1, 1))\n            #x = nn.Sigmoid()(x)*100\n            #loss = nn.BCEWithLogitsLoss()(x, targets.view(-1, 1))\n            metrics = self.monitor_metrics(x, targets)\n            return x, loss, metrics\n        \n        return x, 0, {}","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:18:49.232470Z","iopub.execute_input":"2021-11-22T00:18:49.232742Z","iopub.status.idle":"2021-11-22T00:18:49.247568Z","shell.execute_reply.started":"2021-11-22T00:18:49.232706Z","shell.execute_reply":"2021-11-22T00:18:49.246361Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## aug all","metadata":{}},{"cell_type":"code","source":"train_aug = albumentations.Compose(\n    [\n        #albumentations.RandomResizedCrop(\n        #    height=args.image_size, width=args.image_size, \n        #    scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), p=0.5\n        #),\n     \n        albumentations.Resize(args.image_size, args.image_size, p=1),\n     \n        albumentations.HueSaturationValue(\n            hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5\n        ),\n     \n        albumentations.RandomBrightnessContrast(\n            brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5\n        ),\n     \n        albumentations.ShiftScaleRotate(\n            shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2\n        ),\n     \n        albumentations.HorizontalFlip(\n            p=0.5\n        ),\n     \n        albumentations.VerticalFlip(\n            p=0.5\n        ),\n    \n        albumentations.OneOf([\n            albumentations.IAAAdditiveGaussianNoise(),\n            albumentations.GaussNoise(),\n        ], p=0.2),\n\n        albumentations.OneOf([\n            albumentations.MotionBlur(p=.2),\n            albumentations.MedianBlur(blur_limit=3, p=0.1),\n            albumentations.Blur(blur_limit=3, p=0.1),\n        ], p=0.2),\n\n        albumentations.OneOf([\n            albumentations.OpticalDistortion(p=0.3),\n            albumentations.GridDistortion(p=.1),\n            albumentations.IAAPiecewiseAffine(p=0.3),\n        ], p=0.2),\n     \n        albumentations.OneOf([\n            albumentations.CLAHE(clip_limit=2),\n            albumentations.IAASharpen(),\n            albumentations.IAAEmboss(),\n            albumentations.RandomBrightnessContrast(),            \n        ], p=0.3),\n\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\n\nvalid_aug = albumentations.Compose(\n    [\n        albumentations.Resize(args.image_size, args.image_size, p=1),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T06:40:01.938702Z","iopub.execute_input":"2021-11-19T06:40:01.939344Z","iopub.status.idle":"2021-11-19T06:40:01.95389Z","shell.execute_reply.started":"2021-11-19T06:40:01.939301Z","shell.execute_reply":"2021-11-19T06:40:01.953102Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## base aug","metadata":{}},{"cell_type":"code","source":"train_aug = albumentations.Compose(\n    [\n        #albumentations.RandomResizedCrop(\n        #    height=args.image_size, width=args.image_size, \n        #    scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), p=0.5\n        #),\n     \n        albumentations.Resize(args.image_size, args.image_size, p=1),\n\n        albumentations.HorizontalFlip(\n            p=0.5\n        ),\n     \n        albumentations.VerticalFlip(\n            p=0.5\n        ),\n\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\n\nvalid_aug = albumentations.Compose(\n    [\n        albumentations.Resize(args.image_size, args.image_size, p=1),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:18:49.249173Z","iopub.execute_input":"2021-11-22T00:18:49.249801Z","iopub.status.idle":"2021-11-22T00:18:49.259349Z","shell.execute_reply.started":"2021-11-22T00:18:49.249721Z","shell.execute_reply":"2021-11-22T00:18:49.258529Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"%%time\nfor fold_ in range(args.fold):\n    print('#'*25)\n    print('### FOLD',fold_+1)\n    print('#'*25)\n    \n    df_train = df[df.kfold != fold_].reset_index(drop=True)\n    df_valid = df[df.kfold == fold_].reset_index(drop=True)\n    \n    train_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_train[\"Id\"].values]\n    valid_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_valid[\"Id\"].values]\n    \n    train_dataset = PawpularDataset(\n        image_paths=train_img_paths,\n        dense_features=df_train[dense_features].values,\n        targets=df_train.Pawpularity.values,#/100.0,\n        augmentations=train_aug,\n    )\n\n    valid_dataset = PawpularDataset(\n        image_paths=valid_img_paths,\n        dense_features=df_valid[dense_features].values,\n        targets=df_valid.Pawpularity.values,#/100.0,\n        augmentations=valid_aug,\n    )\n    \n    model = PawpularModel('swin_small_patch4_window7_224', train=True,\n                           head_out=args.head_out, features=args.features)\n    \n    es = EarlyStopping(\n        monitor=\"valid_rmse\",\n        model_path=f\"model_f{fold_}.bin\",\n        patience=3,\n        mode=\"min\",\n        save_weights_only=True,\n    )\n\n    model.fit(\n        train_dataset,\n        valid_dataset=valid_dataset,\n        train_bs=args.batch_size,\n        valid_bs=args.batch_size,\n        device=\"cuda\",\n        epochs=args.epochs,\n        callbacks=[es],\n        fp16=True,\n    )\n    \n    del df_train, df_valid, train_img_paths, valid_img_paths, train_dataset, valid_dataset\n    gc.collect()\n        \n    if ONLY_FIRST_FOLD:\n        break","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:18:49.260828Z","iopub.execute_input":"2021-11-22T00:18:49.261171Z","iopub.status.idle":"2021-11-22T01:07:28.762195Z","shell.execute_reply.started":"2021-11-22T00:18:49.261133Z","shell.execute_reply":"2021-11-22T01:07:28.761491Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:07:28.766767Z","iopub.execute_input":"2021-11-22T01:07:28.767440Z","iopub.status.idle":"2021-11-22T01:07:29.499822Z","shell.execute_reply.started":"2021-11-22T01:07:28.767400Z","shell.execute_reply":"2021-11-22T01:07:29.498988Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir(r'../working')\nfrom IPython.display import FileLink\nFileLink(r'model_f0.bin')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:07:29.502989Z","iopub.execute_input":"2021-11-22T01:07:29.503209Z","iopub.status.idle":"2021-11-22T01:07:29.511416Z","shell.execute_reply.started":"2021-11-22T01:07:29.503182Z","shell.execute_reply":"2021-11-22T01:07:29.510697Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}